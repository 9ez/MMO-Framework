/*
Author: Gudakov Ramil Sergeevich a.k.a. Gauss 
Гудаков Рамиль Сергеевич 
Contacts: [ramil2085@mail.ru, ramil2085@gmail.com]
See for more information License.h.
*/

 Дата создания 1.12.2011

    DONE
    BUG
    INFO
    

    DONE: 

21.12.2011:
 - TList. Список с блокировкой, для операций над элементами из разных потоков.
 - отладка транспорта.
25.12.2011:
 - первый ответ от сервера.
 - произошел коннект между клиентом и сервером.
 - логирование и отладка транспорта.
26.12.2011:
 - версия при попытке соединиться.
27.12.2011:
 - транспорт контроль свежести пакета.
 - механизм дисконнекта.
28.12.2011:
 - асинхронный вызов списка клиентов в окне сервера.
30.12.2011:
 - Сервер: список клиентов перевести в TArrayObject для повышения скорости.
 - свежесть пакета при потере соединения synchro.
 - два типа CN - стрим и пакетный в транспорте.
06.01.2012:
 - уведомление о приеме Stream и Packet.
07.01.2012:
 - контроль соединения - разрыв на клиенте и сервере, 
 - клиент: разрыв по 1. отсутствию пакетов от сервера 3 секунда и 2.по событию Disconnect от транспорта.
 - сервер: разрыв по отсутствию пакетов от клиента 1 минута -> 1.событие Disconnect от транспорта. Всегда отсылка раз в минуту Эхо.
 - Стрим для гаража.
 - время для массива клиентов сервера: отсылка и прием. раз в минуту отсылка Эхо.
 
10.01.2012:
 - отладка транспорта
 - добавлено управление клиентом с помощью скрипта.
 - лог стрима.
 - лог клиента по нику.
11.01.2012:
 - тестирование транспорта с 220 клиентами.+
 - тестирование транспорта с 450 клиентами.+

13.01.2012:
 - Блин, разрушил транспорт :(. Неувязки с многопоточностью.
   Разобрался: Клиент отправляет по неизвестному транспорту адресу, но не получит от НЕИЗВЕСТНОГО.
               Сервер наоборот: отправит по известному, но получит от неизвестного.
               Поэтому не возникнет ситуации когда будет добавление из двух потоков.
               НО 

14.01.2012:
 - Лог транспорта, события.
 - Список ожидающих отправления и список ожидающих подтверждения mArrWaitSend и mArrWaitCheck.
 - Очередь на отправку у транспорта.
15.01.2012:
 - отладка: вывод в файл процента нагрузки главного потока сервера.
16.01.2012:
 - Загрузка списка танков в гараже.
17.01.2012:
 - Выбор танка в гараже.
18.01.2012:
 - Форма ожидания боя и запрос на бой.
 - Запрос на бой обработан и сформирована команда.
 - Зачатки балансера.
19.01.2012:
 - Стрим для начала боя
21.01.2012:
 - Думаю над зонами и картами, физикой и боем. Это все надо как-то увязать.
25.01.2012:
 - Обратный отсчет перед боем на сервере.
 - Обратный отсчет перед боем на клиенте.
12.04.2012:
 - DXUT + DirectX + Qt4
14.04.2012:
 - Начал реализацию архитектуры на основе DirectX
15.04.2012:
 - Симбиоз DirectX и Qt4 для графики - там все просто TBaseDirectX с функциями отрисовки и событий.
17.04.2012:
 - Переделываю протокол общения Клиент-Сервер с учетом графа сценария поведения. Я думаю это дня на 2-3.
 - Установка Git. Это предложение тест для него. Пока работает. Но муть полная. Думаю, можно привыкнуть.
18.04.2012:
 - Корректирующий пакет отправляется группой не более 5-10 событий в пакете. Пакеты помещаются в TransportMain
 в независимости от кол-ва пакетов.
 - Придумал как будут взаимодействовать потоки DX и Transport Main при обмене корректирующих пакетов и стрима.
 Будут меняться непосредственно параметры объектов MultiThreadQueue. - 
19.04.2012:
 - Проверка ClientMain +
 - Проверка GameRoomPrepare +
 - Проверка WaitForm +
20.04.2012:
 - Появился ManagerGUI. Он управляет окнами клиента. Также управляет загрузкой компонентов для проведения боя и обрабатывает ответы от сервера.
21.04.2012:
 - Вставить время в Queue.
22.04.2012:
 - Мучаюсь с TA_In_Fight. Разная длина sNick и cnt Tank.
28.04.2012:
 - Реализовал TA_In_Fight. Этот класс готов для масштабирования.
01.05.2012:
 - Отдыхал. Не мог даже смотреть на проект. Похоже, что на работе рабочее место лучше. Определенно лучше.
02.05.2012:
 - Угу, лучше.
03.05.2012:
 - Логирование DirectX.
 - Кольцо работает. DirectX и транспорт обмениваются данными.
 - Подвод данных к комнате.
 - Отсылка запроса корректирующего пакета.
05.05.2012:
 - Доработка TRoom.
09.05.2012:
 - Доделал транспорт(все тесты проходит). Думаю над графикой.
10.05.2012:
 - Обнаружил странный глюк в Студии: иногда сервер может падать из-за того что 
 CRT обнаруживает запись в память после закрытия сервера. В ~TGarage().
 Помогает ребилд проекта.
11.05.2012:
 - Работа над ModelDX, ManagerModelDX.
14.05.2012:
 - Добавлен EditorModel.
17.05.2012:
 - Работа над Editor. Загрузка данных из ini-файлов.
18.05.2012:
 - Заработал графический движок. Нарисовал первый объект :)
21.05.2012:
 - Вчера скачал программку для конвертации из primitives в x формат.
  Загрузчик надо переделать под этот формат. Теперь надо нарисовать хотя бы танк.
  3D Object Converter
  Конвертируем из primitives в *.obj (WaveFront). Далее используем для помещения в Mesh класс
  Порядок действий при конвертации:
  1. Загрузка модели.
  2. Options->Export->WaveFront поставить галочку Export Vertex Normals
  3. Tools->Flip Scene UV Map Vertically.
  4. Save as WaveFront.
  5. Подправить *.mtl и привести примерно к такому виду: 
                newmtl Material_1
                Ka 0.4 0.4 0.4
                Kd 0.587609 0.587609 0.587609
                Ks 0.171744 0.171744 0.171744
                illum 5
                Ns 8.000000
                map_Kd PzVl_Tiger_I.dds
 - Консервация проекта. 
11.06.2012:
 - Добавлен SelfTank, думаю о изменении интерфейса класса ManagerDirectX.
14.06.2012:
 - Проект под лицензией GPL.
 - Melissa - транспорт, BigJack - графика, Robert - физика, Клиент(GUI) -- для лучшего понимания архитектуры
 - Основное положение для протокола: сервер на прикладном уровне управляет Клиентом и BigJack.
Т.о. это как бы два прикладных протокола.
05.07.2012:
 - Добавлена возможность Qt + DirectX Qt4.5.0.
 - Консервация проекта с веткой на основе DXUT. Развитие ветки Qt+DX.
19.07.2012:
 - Консервация. Серьезные архитектурные изменения. Приводится в порядок модульная структура проекта.
ITBaseObject, TanksLib.lib, TManagerGUI, TBaseGUI_DX.
 - Нашел простые редакторы моделей OBJ. По идее EditorModel пока не нужен.
07.08.2012:
 - Общая архитектура в Enterprise Architect.
08.08.2012:
 - Оживил Клиента и Сервер. С новой архитектурой. (doc/Общая архитектура.EAP)
 - Версия v0.040
15.08.2012:
 - Почти запустил BigJack. Осталось доделать IBaseObjectDX::SetModel - установить матрицы.
20.08.2012:
 - Улучшил TCallbackRegistrator, добавил std::set<...>.
29.08.2012:
 - Перешел на DXUT. Теперь поток Qt работает в DXUT.
 - BigJack заработал. Дело было в том, что Subset в DrawSubset был равен 0, а должен быть равен 1.
30.08.2012:
 - Перешел с формата *.obj на *.bj, убрал лишнюю загрузку текстур и компиляцию шейдеров и снизил время загрузки
 с 5 секунд до 73 мс. *.bj - бинарный формат хранения Mesh. BigJack формат.
31.08.2012:
 - Разбираюсь с матрицами. Думаю как сделать привязку частей модели друг к другу по-умолчанию.
03.09.2012:
 - ЛОЛ в WOT XZ находятся внизу, а Y это стрелка уходит вдаль.
10.09.2012:
 - Анимация: разделение объектов на чисто анимированные и "грязно".
16.09.2012:
 - Болею,  голова вообще не соображает. Потом Tree доделаю.
 - Модели в ВОТ зеркальные.
20.09.2012:
 - Умею вращать башней и двигать пушкой у танка.
27.09.2012:
 - Добавлена поддержка XML формата. Чтение, запись. Через CMarkup.
 - Перенаправил поток событий на Qt от DXUT.
01.10.2012:
 - Сделал Менеджер ресурсов. Осталось Довести до ума шейдерный стек и камеру. И движок будет закончен.
02.10.2012:
 - Добавлено отображение фпс.
04.10.2012:
 - Пытался научить движок делать объекты прозрачными. Не получилось сразу.Дело в том, что 
 прозрачность разных объектов определяется порядком их построения. Рендер прозрачных нужно
 производить в самую последнюю очередь. Причем кол-во прозрачных объектов в движке
 ограничено (если больше выглядит не очень красиво). Проблема решается сортировкой по расстоянию от камеры.
 Но данная проблема не критична. Если понадобится - решу в будущем.
31.10.2012:
 - Переделка архитектуры. Идея: События генерирует Qt класс (точнее происходит перехват WinApi 
 и отсылка в Qt обработчик, далее событие обрабатывается ManagerEvent). Т.о. стало возможным 
 перехватывать и GUI события. В общем достаточно пронаследоваться не от Qt, а, например, от другого GUI.

05.11.2012:
 - Возникла идея по симбиозу Qt и DirectX. Суть идеи (всего две, надо определить ту что быстрее):
 1. Берем буфер из DXUT вставляем его в QImage и отдаем на QWidget. Далее рендерим GUI с параметрами Alpha. - так думаю что будет медленнее.
 2. Рендерим элементы GUI и отдаем в DXUT. Там средствами DirectX происходит альфа-смешивание и окончательный рендер.
 Время выполнения:

06.11.2012:
 - Qt+DXUT = R.I.P.
 Время на выполнение слишком велико. На WinXP 30 мс, а на Win7 200 мс (!!!). Но это для первого способа.
 Есть второй способ. Но это не исправит ситуации. Конвертации Qt->DXUT и наоборот слишком медленны.
 Виден только один  способ - DXUT Native GUI. Но прежде надо продумать архитектуру с учетом источников
 событий. NET, GUI, LoadFromHDD, Key+Mouse и т.д. Есть модуль управления(МУ) движком игры. Он имеет определеный интерфейс,
 МУ берет настройки для конвертации внешних событий из файла в зависимости от внешнего воздействия. Надо проанализировать
 схему работы с DGUI, подумать над интерфейсом МУ и связи с MOC. Но завтра надо доделать ОПП.
08.11.2012:
 - Для всех классов GUI DXUT сделать виртуальным деструктор. 
 - Разобраться с технологией GUI DXUT.
12.11.2012:
 - Была идея создания TankLib(классы, которые характерны для игры танки), но считаю в этом необходимости нет.
В идеале все пишется на Python и "превращается" в С++ классы в менеджере Компонентов.
Но пока я не освоил эту технологию, буду все классы держать в GameLib 
(например, TMakerObject, метод NewByID_Behavior()). Потом уберу оттуда в Python.
21.11.2012:
 - Нафиг Python. Пишется DLL. У нее три функции GetClientDeveloperTool(),
GetServerDeveloperTool() и Done(IDeveloperTool*). Функции возвращают объекты, интерфейс которых определен в движке.
IClientDeveloperTool и IServerDeveloperTool. Не понимаю смысла в использовании
Python. Все пишется на C++. Просто необходимо обрабатывать события в данных объектах.
Также Developer должен переопределить поведение объектов на сцене(наследуется от IBaseObjectGeneral) и 
способ их создания (IMakerObjectCommon). Тот объект, который активно участвует в сцене, наследуется
от IActor. Далее для работы с GUI Developer наследуется от IGrahpicEngineGUI. В конструкторе
вызывает Load(путь к XML). Далее Connect(компонент,событие,обработчик).
 - Далее мышь и клавиатура: у IClientDeveloperTool есть метод int ConvertKeyEvent2Value(...) и 
int ConvertMouseEvent2Value(...). Значение, полученное от этих функции подается 
на логический уровень. Механизм конечного автомата по значению найдет ключ. Данный ключ для обработки
передается в обработчик этих ключей.

23.11.2012:
 - См. Architecture v0.4.eap и Architecture Included Headers.eap.
 - Game.exe -a s/c -p client.dll --p start with param ip=0.0.0.0 port=1000
 Т.е. Игровой движок один. параметры разные. Как то так:
 if(argv[1]=='s')
   new TClient
 else
   new TServer
25.11.2012:
  - Типы игр: Local, Online, Massive-Online. К слову о Master-Server, Slave-Server и Client.
  Local - в одном процессе, остальные в разных потоках.
26.11.2012:
  - Massive-Online - Система MasterServer-SlaveServer. Оптимизация. Распределение нагрузки и 
создание общей точки синхронизации.
Задачи Master - 1. Первичная точка доступа при регистрации соединения с абонентами.
                2. Распределение нагрузки среди Slave.
                3. Поиск по запросу у MasterServer и SuperServer соединения с Клиентом по его нику.
                4. Решения о синхронизации.
  - Муть с архитектурой. Пока GUI и GE доделаю. Совершенно не понятно что должно быть предоставлено 
  разработчику и как все это реализовать.
27.11.2012:
  - Будет каркас у сервера. Разработчику надо будет переопределить методы сервера.
28.11.2012:
  - Интерфейс GameLib.lib : 
  1. Client-Оффлайн, 2. Client-Онлайн, 3. Slave-Master, 4. Slave, 5. Master, 6. SuperServer.
  + путь к *.dll    
  - Скомпилировал и слинковал :)
  - Начинаю делать DLL.
29.11.2012:
  - Конвейер графического движка работает. Главный конвейер клиента тоже работает.
07.12.2012:
  - Мысли: 1. Камера должна быть в GameLib(Композиция). ICamera находится в Share. Звук и графика 
  владеют как агрегацией камерой.
  2. У объекта три сущности - графика, физика и звук.
  - Пока разбираюсь с выбором GUI. На выбор: MyGUI, CEGUI, Antisphere, librock, GWEN, Janella(мать 
  этих испанцев итить) и еще куча всякой хрени.
08.12.2012:
  - Вчера принял решение о переходе на MyGUI. Для освоения этой технологии необходимо:
  1. Собрать самостоятельно MyGUI_Engine.lib(dll). - от 1 недели до 1 месяца.
  2. Собрать Platform. - 1 неделя
  3. Собрать BaseManager (прослойка для работы с MyGUI). 1-2 дня
  4. Собрать пример для подтверждения того что владею технологией (демонстрация). 1-2 дня
  Заменять ли DXUT на MyGUI будет ясно на 2-3 этапе.
  - Данную версию считать свежей. Эксперименты здесь я пока не проводил. Ясно одно что настоящий 
  костяк конвейера клиента останется нетронутым. Добавится лишь GUI.lib, ну или еще заменится ли 
  DXUT на Platform.lib.
  - Архитектура точно будет известна  после 2-3 этапа (как раз когда будет известно будет ли жив DXUT).
11.12.2012:
  - За два дня скомпилировал и слинковал MyGUI!
  - Все работает и не тормозит в отличии от CEGUI.
  - Осталось придумать как это внедрить в multiplayer.
14.12.2012:
  - Тестовый пример собран. Заметил что обработка событий съедает львиную долю времени (до 12-15 мс)
от кадра. Если вырубить обработку событий будет под 1000 fps.
  - Потрачу время на Wrapper_MyGUI_Export. Мне кажется в этом что-то есть.
  завтра буду доделывать внедрение MyGUI. Потом Камера.
15.12.2012:
  - До сих пор делаю GUI. Все несколько сложнее чем казалось.
  Не хватает TManagerGUI. Static GetComponent.
19.12.2012:
  - Встраиваю GUI.lib в проект. Структурировал solution.
20.12.2012:
  - Доделал GUI. Столкнулся с одной проблемой, но решил ее.
  Дело вот в чем: если использовать статически скомпилированную библиотеку типа lib
для Exe и DLL, то это будет два разных адресных пространства.
Поэтому нужно компилировать MyGUI в виде DLL.
  - Есть одна недоделка - при переходе в full-screen происходит ResizeGUI, но когда
обратно ResizeGUI не проходит.
  - Задача - глюк с Tools GUI, resize, Camera, конечный автомат, 
21.12.2012:
  - Исправил глюк с некорректным ResizeGUI. Дело в том что DXUT вызывает Reset до реального
изменения размера окна. Мне кажется так и должно быть. Reset так и должен себя вести.
Сырость DXUT в том что нет события "переход в из оконного режима в полно экранное и обратно".
22.12.2012:
  - Блин. Когда создавал проект MyGUIEngine это был Dll-проект. Потом я его переделал в Lib.
А вот EditorFramework был изначально как Lib. Надо было не менять тип проекта, а создавать заново.
В проекте прописать define MYGUI_BUILD_DLL и все.
25.12.2012:
  - Мысль назвать игровой движок FullMaster или Tornado.
  Танки - это всего лишь пример использования. Надо поправить заголовок файлов.
26.12.2012:
  - Добавил класс контроля за кол-вом создаваемых объектов одного класса.
  Теперь если нужно ограничить кол-во создаваемых объектов нужно пронаследоваться
  от TOnly_N_Object и указать в конструкторе макс. кол-во объектов и 
  макросом NAME_CLASS прописать имя класса.
  - Перевожу GBaseLib, Share из Lib в Dll (надо так же и проект модулей конвертировать в Dll).
  - Потом нужно править архитектуру.
27.12.2012:
  - Делаю камеру. Для этого надо подготовить классы матриц (оптимизация).
  Оптимизирую: по сути в памяти у DX и Struct3D одно и тоже.
  Это можно применить в операциях над классом. А вот преобразовывать из Struct3D в DX 
  и наоборот придется что-то еще придумать.
09.01.2013:
  - Заменил все классы типа TMakerXXX на макрос.
  - Новогодний застой заканчивается. Все каникулы занимался поеданием еды, 
  играми и ничего-неделаньем.
  - Пусть будет имя "TornadoEngine"
11.01.2013:
  - Какие-то результаты по камере.
13.01.2013:
  - Сделать orient и учет координат и углов камеры. Учет больших изменений (list<>).
15.01.2013:
  - Основная проблема сейчас - непонятно поведение реализации класса TCamera. Нужно четкое определение.
  Думаю, лучше разделить на мелкие части с простым описанием и, комбинируя этими маленькими методами, 
  реализовывать крупные.
16.01.2013:
  - Наконец-то работает LookAt у камеры. Теперь, задав вектор нормали к Земле, можно управлять Roll камеры.
18.01.2013:
  - Составил План работ.
  - Сделал настройку путей к ресурсам движка (модули).
29.01.2013:
  - Конечный автомат готов. Для мэппинга клавиатуры(системные события) и HotKey.
  - Гибкий контейнер готов. Нужен в будущем для упаковка пакетов прикладного уровня.
  в нем сначала нужно описать схему контейнера (задать вектор). Далее, получив доступ
  по имени к памяти, назначить содержимое. В случае изменения кол-ва полей 
  вызвать Update().
30.01.2013:
  - Читаю boost. Тут есть все, что нужно. Подумываю над внедрением технологии.
  Можно заменить TMapDual на boost::bimap, TStateMachine на boost::msm.
07.02.2013:
  - Client знает о неком протоколе общения с абстракцией "сервер". 
  Сервер-Slave о таком протоколе ничего не знает (требуется только 
  переопределить чистые виртуальные методы).
08.02.2013:
  - Добавил в камеру привязку к объекту, перемещение свободной камеры с заданием скорости.
11.02.2013:
  - Делаю клиент-серверные отношения.
13.02.2013:
  - Освоил кватернионы. Применил в камере вместо корректировки по нормали к Земле.
  Всего 2 строчки кода заменяют огромное кол-во формул и расчетов. Очень удобно.
23.02.2013:
  - Правлю транспорт. Проблема в том максимальный размер пакета по UDP 1,5к.
  Значит если потребуется отправить пакет большего размер, нужно будет использовать либо класс-дозатор
  (дробление пакета и сборка) либо TCP канал.
  Еще существует проблема эффективного использования канала:
  либо засорить его полностью (когда пакеты отправляются без ожидания отправки предыдущих пакетов),
  либо неэффективно использовать (ожидание отправки предыдущих пакетов).
  Эта проблема может иметь место как на сервере (чаще всего) так и на клиенте.
28.02.2013:
   - Пока правлю транспорт. Систему массового обслуживания прежде надо разработать верхушку.
   Потом двигаться сверху в низ, выставить требования к интерфейсу транспорта. А не наоборот.

30.04.2013:
  - Разработка интерфейса Мелиссы закончена. Теперь надо удалить текущую Мелиссу из проекта и заменить
  на Melissa.dll и NET_Transport.dll.
  - По плану нужно релизовать абстрактные классы интерефейса.
  - Для Melissa все-таки придется использовать классическую схему, которую используют при разработке Qt.
  То есть вся иерархия классов не чисто абстрактная.

04.05.2013:
  - Требуется реорганизация Share и GBaseLib (сделать после Melissa):
   1. удалить неиспользуемые файлы.
   2. сделать прослойку между внешним пользователем и glib.
   3. переименовать библиотеки.
   4. переместить файлы в соответствующие библиотеки (Share<-->GBaseLib).
  - Доделать NET_Transport, Melissa и добавить DBLib (декабрь 2013).
07.05.2013:
  - Для переключения транспорта TNetTransport в быстрый режим надо прописать в свойствах проекта
  FAST_NET_TRANSPORT. Он выключит логирование, тем самым повысит скорость обработки пакетов.
  - Проблема нагруженности сервера при получении пакетов на высоких скоростях (более 100 Мбит/с).
  Не так критична, поэтому решаться должна после написания Melissa.
  Идеально для 100 Мбит 10 мс задержка и 150-250 пакетов в одной посылке (для NetDoser эта 
  информация будет полезна).
  - Идея для Дозера: при попытке отправить решать больше ли пакет определенного размера.
  Если больше, то будить поток и отправлять с помощью него так, что бы не перегружать трафик и сервер.
  Если меньше то просто отправить.
03.06.2013:
  Фактически транспорт готов
07.06.2013:
  После долгого и нудного обдумывания прихожу к выводу что нужно строить транспорт на TCP/UDP.
  В TCP десятилетиями апробировались технологии управления трафиком. Поэтому изобретать велосипед не буду.
  Стоит лишь научиться управлять TCP таким образом что бы контролировать процесс и подстраивать его под свои нужды.

  На высоких скоростях отрабатывал "вдумчивый" TCP, а на низком трафике быстрый и без инерционный.
09.06.2013:
  Два последних дня был в прострации. Думаю подсознание перезагружалось.
  Значит так: открывать один и тот же порт для TCP и UDP можно.
  connect под Windows работает с блокировкой.
  WSA_XXX может отслеживать события на Socket-ах.
  Осталось выяснить можно ли писать и читать в сокет из разных потоков.
14.06.2013:
  Более того можно открывать один и тот же порт для listen и для connect. 
  Надо использовать флаг reuse для сокета.
16.06.2013:
  Сетевой транспорт готов. Но не обошлось и без проблем.
  Дело в том что, при малом размере буфера на прием при передаче данных по TCP
  пакеты перетираются свежими пакетами. Думаю проблема в использовании на localhost или в WSA.
  Пока это неважно. Оставляю проблему до 17 июня. А сейчас Melissa (СМО).
21.06.2013:
  Проблема решена. Все дело в том что надо было отслеживать готовность отправить пакет по возвращаемому значению
  функцией send. Пакеты не затирались, они не были отправлены.
  Готовность к сборке Melissa. Но сначала надо собрать каркас серверного конвейера. Это я не учел.
  На это может уйти до 2-3 недель. Тут надо учесть возможность использовать в разных воплощениях.
  Как только конвейер будет готов, можно будет делать внутренности Melissa.
28.06.2013:
  Делаю конвейер сервера, точнее Slave реализацию. Наконец-то сдал ИТОК.
  Спать охота, часто засыпаю, когда никого нет. Зато после сна часто возникают интересные
  идеи.
02.07.2013:
  Я на распутье. Дело в том, что в качестве Графического движка можно использовать кучу бесплатных
  движков. С физикой дела обстоят так же. MyGUI я уже использую. А вот сетевых движков нет.
  Либо они платные, либо кривые и бестолковые.
  Таким образом все что от меня требовалось, так это написать игровой и сетевой движок.
  Но графический движок написан. На данный момент нет такой необходимости в выборе между графическими движками.
  Самое главное сейчас доделать Сервер, Melissa и внедрить физику.
  1. Доделать серверный конвейер (тяжко, спать охота) с учетом назначения Slave, Master, SuperServer.
  2. Доделать Melissa. Тут вся проблема в критерии готовности библиотеки. Нет тестов
  для точного понимания того, что все готово.
  Балуюсь Newton и Bullet(хотя нужно другим заниматься!). Они конкуренты, надо бы еще раз
  скачать ODE (она мне в первый раз не понравилась).
03.07.2013:
  Поправил TNetTransport_UDP. Заменил TArrayObject на std::map.
  Код стал меньше и понятнее. Вдобавок я избавился от зависимости от GBaseLib.
  Этот класс можно будет использовать там, где нет TCP.
  Думаю завтра начну править серверный конвейер, сегодня спал с 23-00 до 6-20. 
  Голова лучше соображает, чем вчера :). Мысля копится, думаю скоро разрожусь.
04.07.2013:
  Надо разработать внутренний протокол общения Мелиссы.
  Выбор стоит по внутренней организации классов Мелиссы.
  Либо делать очередь событий, куда будут складироваться события от транспорта 
  (обрабатывать их в Work), либо сразу напрямую обрабатывать события и добавлять в TSrcEvent.
  Во втором варианте метод Work выполняет роль таймера, например, если
  нужно ждать ответа от сервера на запрос.
07.07.2013:
  Проанализировал кучу сетевых движков, ни одного нормального.
  Во всех исходниках нет даже std::map, не то что Boost-а.
  RakNet вообще кидалово. Cloud за 100$ в месяц.
08.07.2013:
  Менеджер сессий готов. Теперь надо найти общее между всеми сценариями
  и поместить в TBase.
11.07.2013:
  Все таки решил использовать BulletPhysics.
  1. Код Bullet более качественнее. В Newton-е код сырой, хотя фич по отладке больше.
  То же самое что выбирать между мониторов с плохим качеством отображения, но с закрепленным на нем
  зонтиком, открывашкой для пива и ручкой на веревке, и качественным монитором, но без подставки.
  В движке главное качество кода и возможность для наращивания функционала, а в Newton эти возможности
  уже нарастили, но код сырой.
  2. Bullet используется в GTA 5, а это уже что-то да значит. Более шикарных аварий при столкновении
  автомобилей в играх я никогда не видел.
  3. Взгляд больше цепляется за Bullet, приятнее разбираться - скорее как бонус, не сильный аргумент.
18.07.2013:
  Вроде транспорт сделал, а сейчас гляжу - максимум то для функции WSAWaitForMultipleEvents сокетов
  равен 64. Под Windows XP это точно. Надо посмотреть как под Windows 7 и под Linux (poll).
  Как выход - либо опрос сокетов частями по 64 сокета, либо через RegisterWaitForSingleObject.
19.07.2013:
  Ха! В очередной раз охреневаю от MS. Есть такая функция WSAPoll, но она доступна с Windows Vista.
  Аналог poll, надо смотреть сколько можно сокетов отслеживать. Если будет достаточно
  много (хотя бы 500), то можно будет под Windows XP использовать многопоточную схему, а под
  Windows 7 WSAPoll.
22.07.2013:
  На фиг WSAPoll. С помощью потоков и событий ждать события от сокета.
  MainThread владеет hEvent, другие рабочие потоки сообщают с помощью SetEvent
  о получении пакета.
24.07.2013:
  Boost использует Completion Port под Windows (очень мощная штука). 
  Пока сделал транспорт на WSAWaitEvent,
  теперь добавлю транспорт, основанный на Boost(но старый транспорт оставлю). Использую Boost 1.54.
  Т.о. будет 3 вида транспорта (Boost, TCP_UDP(Win32) и UDP(Win32/Linux)).
25.07.2013:
  С вводом boost можно полностью отказаться от glib и GBaseLib. Сократит кол-во исходников,
  но в то же время будет жесткая завязка на boost.
06.08.2013:
  С помощью boost asio под Windows XP максимальное кол-во соединений - 156, 
  под Windows 7 - 500 (и это не предел).
  Перешел с async_connect на connect, теперь стало 220, но думаю дело не в этом, либо
  памяти мало либо ОС другую надо.
  Странно поведение CPU Intel Core2Duo E6400. Не тянет(до 100%) даже 100 UDP 1000 мс 1 пакет по 1350 байт,
  хотя Intel Core2Duo E8400 и Core2Duo E7400 тянут хоть 220, даже не напрягаясь (2-5%).
  И не понятно то ли дело в процессоре, то ли в ОС, то ли в объеме памяти.
  Дома то у меня Win7, 4 Гб и все тянет спокойно. В любом случае движок уже на что-то да способен.

  Будем считать что транспорт готов. Главное что бы комп держал 
  20 пакетов по 1350 байт с задержкой 100 мс на 500 клиентов (что эквивалентно 10000 клиентам
  на 1 пакет на 100 мс). Что для пакета в 1350 байт ооочень много, обычно пакет размером 100-200 байт(то есть 
  запас в 10 раз, а это вообще 100 000 клиентов). "Держать" - значит нагрузка 10-20% от одного ядра. 
  Что бы оставалось время на другие задачи. То есть для 4 ядерного процессора надо примерно 5% от общей нагрузки.
  Для сервера использовать CPU x8 Xeon X5550HT 2666 MHz (надо стоимость узнать).
07.08.2013:
  CPU x8 Xeon X5550HT 2666 MHz стоит 1600$, но это для многопроцессорных систем. Думаю
  Intel Core i7 (1000$ с 6 ядрами) хватит, 32 Гб памяти.
14.08.2013:
  BOOST_FOREACH нельзя работать с map и set, если нужно менять содержимое внутри.
  Проблема решена: использовать BOOST_FOREACH(TMapClass::value_type& bit, mMap)
	                                bit.second->Func();
27.08.2013:
  Вход Slave в состав кластера готов.
  Завтра надо будет сделать авторизацию клиента.
29.08.2013:
  Для сценариев решил переделать механизм обмена пакетами. Модель Self-To-Self, то есть
  один класс сценария передает данные тому же классу, т.о. владелец сценария не знает о типе
  пакета, а знает лишь какому сценарию предназначен пакет.
  Доделать контекст сценария, продумать.!!!!!!
30.08.2013:
  Что бы сразу разобраться по сценариям:
    1. Сначала была идея создания сценария для одной цели. То есть уровни, владеющие
  сценариями не знают о типах пакетов. Пакеты передаются объекту, который решает
  какому сценарию предназначен пакет. Далее сценарий решает что делать с пакетом.
  То есть возникает идея Контроля событий сценариев TControlScenario
    2. Далее возникла сложность. Т.к. прием пакетов идет только в сценарии, то создание нового сценария,
  ассоциированного с данным соединением, невозможно. Возникла идея создания контекста сценария - IContextScenario.
  Т.о. сценарий существует всегда, он лишь является моделью поведения. А контекст это данные, с которыми
  работает сценарий. Эти данные привязаны к сессии(хотя могут быть привязаны к чему угодно).
    3. Далее возникает проблема как различать активен ли сценарий? Например, перекоммутация клиента.
  Началась перекоммутация (сократим название - RCM). Контекст ей задан - это C1. Возникла задача объединения
  в группу, значит понадобилась еще одна RCM. Вызвали Begin, спросилил активен ли он.
  Как различить активность? Контекст тот же, сценарий тот же. Ведь вопрос активности
  может задать другое выполнение с тем же контекстом. 
  Решение: bool Begin(IContextScenario* pCSc)
05.09.2013:
  Кое-что о сценариях. Сценарий - модель, контекст сценария - данные. Сценарий
  это своего рода машина состояний, логика.
  Мне совершенно не нравится такой тесный симбиоз (слишком много контекстных функций вызывается
  внутри сценария). Надо бы часть этих вызовов объединять и вынести в функции контекста.
  Ну что бы было больше кода в самом контексте, меньше вызовов типа Context()->.

23.09.2013:
  Вернулся из Турции 18 сентября, пишу только сейчас О_о.
  Есть реальная проблема для визуализации результатов работы движка. И сейчас она ощущается
  очень остро. Сначала сделаю отображение консоли, которая отображается по ключу -c.
  Потом хочу серваку привинтить GUI. GUI можно будет управлять непосредственно через DevTool, 
  но модуль графики будет не таким каким он является в клиенте.
  В таком виде отладка Мелиссы будет эффективней, и работа над проектом будет идти быстрее.
24.09.2013:
  Правлю ядро. Добавляю GUI в сервер. Появляется дублирование кода. Это дублирование 
  надо потом свести в IGame.
  Хехе, fps для сервера то 10! Больше и не надо!
  Все равно данные обновляются не чаще.
26.09.2013:
  Добавил модуль QtLib, теперь для отладки можно использовать GUI.
  Вместо 3 функций использовать 5, заменить GetServerDeveloperTool
  на GetSlaveDeveloperTool, GetMasterDeveloperTool, GetSuperServerDeveloperTool.
  Завтра сделаю.
27.09.2013:
  Все довожу до ума QtLib. Сделал вызов кванта времени из потока Qt для функции.
  Теперь когда нужно что-то изменить в форме, просто вызвать с указанием функции
  и произвести изменения в потоке Qt в какой-то из функций.
03.10.2013:
  Доделать модуль "Таймер"!!!
07.10.2013:
  Доделан Таймер. Поправил ядро с учетом Таймера. Убрал Refresh за ненадобностью.
  Ладно, доделываю LoginClient. Самый тяжелый сценарий, еще тяжелее будет
  перекоммутация, но это фактически 90% всей работы.
09.10.2013:
  Привести в соответствие сценарий LoginClient. 
  ScenarioLoginClient->ColdMaster->HotMaster->Accept или Reject
  Accept -> Queue или Accept (в зависимости от нагрузки серверов)
  -> Context->ScenarioLoginClient
  Проект на Github.com :). Надеюсь, кому-то проект понравится. Но лучше все писать на английском,
  по крайней мере перевести.
10.10.2013:
  Переделываю ScenarioLoginClient, с учетом добавление в очередь ожидания клиента,
  если нет места на серверах.
26.10.2013:
  Идея поместить в ScenarioLoginClient 4 части: Client, Slave, Master и SuperServer,
  каждая из которых отвечает за обработку пакетов, предназначенных, соответственно,
  тезкам. Есть базовый класс, от которого наследуются эти классы, в нем должны быть определены
  все пакеты, а базовый пакет должен быть в ScenarioLoginClient, в нем появляется поле
  char where, то есть кому предназначен пакет, т.о. ScenarioLoginClient определяет
  по нему какой из частей отдать пакет.
  Далее внутри контекста опять таки должно быть 4 части (C,S,M,SS).
  Данное решение имеет своей целью лишь повышение читабельности кода и понижение сложности класса ScenarioLoginClient.
30.10.2013:
  Косметические изменения в проекте. Изменил типы модулей с lib на dll, поменял имена
  с неосмысленных Melissa на MMOEngine и т.д.
07.11.2013:
  Отладка багов работы сценариев. Подкручиваю болты.
08.11.2013:
  LoginClient готов! Осталось проработать варианты обрыва связи на разных этапах выполнения сценария.
  Потом доделать сценарии Дисконнекта клиента. И останется только перекоммутация клиента и все, движок ММО закончен!
  И еще, надо протестировать в интернете авторизацию клиента.
12.11.2013:
  Доделал сценарии DisconnectClient для Клиента и Slave.
  Сценарий LoginClient доделал с учетом надежности (например что делать при дисконнектах на любой стадии сценария).
  Осталось перекоммутация и проверка в интернете.
14.11.2013:
  Оживил Конвертер Меш. При загрузке Клиента Танков загружается Ангар и Тигр II.
15.11.2013:
  Для завершения работ над MMOEngine нужно:
  I Реализовать класс статистики по Клиентам, которые находятся в группе и существуют в системе,
    поместить этого класса в: AddSlave, DeleteSlave, AddClient, DeleteClient, CreateGroup, LeaveGroup,
    DestroyGroup. +
  II 
    1. Обмен для клиентов при формировании Группы на конкретном Slave производится таким образом:
    если Клиент Группы находится не на своём Slave, то он перекоммутируется, а какой-то  другой Клиент,
    который находится на целевом Slave, копируется туда, где находился Групповой Клиент. То есть производится
    обмен, что бы нагрузка была неизменна. Если там нет Клиентов, то не копируется.
    2. Обмен производится для Клиентов не состоящих в Группе только если:
        - контекст Клиента не занят в выполнении сценария перекоммутации.
    3. Поиск Slave, на котором будет находится Группа надо производить по минимуму
    занятых в Группе Клиентам (см. TStatisticaClientInGroup ).
  III
    Доделать сценарии SendToClient и RecommutationClient (он должен быть реализован примерно так же как
    и LoginClient). В этих сценариях не хватает определения что Клиент не успел подконнектиться
    к Slave.

23.11.2013:
  - В движке сделал фокус (управляю танком с сервера на клиенте), 
  думаю всем понравиться. Не очень понравилось. Ну, если я физику сделаю и им не понравится,
  это будет уж слишком.
  - Сделал сценарий рассылки списку Клиентов пакета из любой точки системы (SendByClientKey).
25.11.2013:
  - Правил глюки. Доделал сценарий авторизации Клиента с учетом если Клиент не успел подконнектиться.
  - Остался только сценарий Перекоммутации Клиента сделать и все.
27.11.2013:
  - Глюк при отрисовке на видеокарте GeForce 7600 GS, как будто части отрисовываются без применения
  теста Z буфера. Хотя на встроенных Intel-вских картах и Radeon все отрисовывается изумительно.
29.11.2013:
  - Добавил поверхность в устройство с помощью SetDepthStencilSurface. И проблема решилась.
11.12.2013:
  - Технология RSA и AES из openSSL освоена. Замеры скорости шифрования в doc.
  Вот как это будет:
  1. Этап обмена ключами.
  На уровне транспорта при попытке соединения происходит генерация RSA ключа (Клиент).
  Потом Клиент отсылает в открытом виде публичный ключик Серверу. 
  Сервер генерирует AES ключ и шифрует его публичным ключом RSA Клиента и отсылает Клиенту.
  Клиент дешифрует пакет и теперь ключи AES есть у обоих.
  2. Обмен пакетами, шифрованными с помощью AES. Т.к. AES не скажет была ли попытка подмены, то
  пакет должен быть дополнен MD5 суммой. То есть sizePacket + 16 байт.
  Осталось дооформить замеры и написать классы, реализующие RSA, AES и MD5 для удобства.
12.12.2013:
  - Как в TCP определить наачало и конец пакета? Ведь если прописать в пакете в начале размер и 
  зашифровать, то можно подменить размер и тогда транспорт не только потеряет этот пакет, но и 
  вообще потеряет связь.
14.12.2013:
  - Сделал шифрование. Теперь никто не сможет:
  1. Узнать какими данными обмениваются участники MMO. +
  2. Подменять данные своими (фактически получить управление). +
  3. Уронить сервер. ???
  Но не обошлось и без проблем: генерация ключа для RSA очень интересный процесс.
  Скорость создания ключа варьируется от 200 мс до 7-8 секунд. Таким образом 
  задержка коннекта Клиента к Slave может быть разной. Иногда у Мастера
  таймаут может закончиться. Решение: создание RSA ключа во время запуска приложения.
  RSA ключ один на весь Менеджер ManagerContextCrypt.
16.12.2013:
  - Существует две стороны вопроса о безопасности:
  1. Безопасность Клиента. Что бы нельзя было украсть данные и чтобы нельзя было перехватить управление.
  2. Безопасность Сервера. Что бы нельзя было уронить Сервер и запороть работу Сервера. 
  Первая проблема успешно решена. Используется RSA и AES.
  Вторая проблему несколько шире. 
    Во-первых, можно использовать исходный код Клиента и отправлять некорректные 
  пакеты (проблема Взломанного Клиента). 
    Во-вторых, пакеты, которые летают между компонентами Сервера, можно 
  перехватывать, подменять, менять.
    Проблема Взломанного Клиента решается просто: проверять размер и корректность пакетов Клиента
  в каждом сценарии отдельно.
    Вторая проблема решается невозможностью подмены пакетов. Вставка в начало пакета до шифрования
  счетчика, который увеличивается при отправке. На той стороне контролируют корректность пакета по 
  этому счетчику. Таким образом отправить повторно зашифрованный пакет не получится. Либо его не 
  дешифруют, либо счетчик не подойдет.
    Далее еще один момент Флаг использования шифрования - действует на всю систему в целом.
  Либо он используется и везде в Клиенте, Мастере и т.д. либо нигде.
    Шифруется только TCP. Передавать данные по UDP и пытаться их шифровать - глупо.
  Управляющие команды по UDP не передают. НО есть такой сценарий как ScenarioFlow.
  В нем используется как TCP, так и UDP. В остальных сценариях используется только TCP.
18.12.2013:
  - Перекоммутация завершена! Осталось провести тесты, когда Дисконнект любого компонента может
  произойти в любой момент. И потом можно даже на GitHub выложить.

21.12.2013:
  - Проблема утечки памяти. Не зависит от объема трафика, но зависит от кол-ва пересланных пакетов.
  Растет 1 Мб на одно соединение (каждые 100 мс) за 5 минут на Slave. На Клиенте поменьше в 2-3 раза.
  Решено. Надо было Clean для AES после каждого шифрования.

10.01.2014:
  - Прочитал тут про атаку man-in-the-middle. А ведь моя реализация уязвима.
  Как вариант решения данной проблемы - сертификация сообщений RSA public key.
  А точнее X.509.

13.01.2014:
  - На хрен X.509. Нашел способ решения проблемы MITM. Но для её решения нужно чтобы была
  запись о клиенте в БД.
  Алгоритм:
  1. Клиент отсылает Серверу RSA public key. В ответ AES ключ. Все как обычно.
  2. Сценарий Авторизации: Клиент отсылает MD5(LoginPassword), AES(RSA public key).
  AES зашифрован ключом SHA1(LoginPassword). 
  MD5(LoginPassword) нужен для поиска записи о Клиенте в БД.

  То есть для реализации алгоритма всего то надо добавить дополнительную функцию в Сценарий и новый
  ответ Сервера IsSessionSecurity.
  
  1. RSA
  2. MD5(LP), AES(RSA), key for AES is SHA1(LP)
14.01.2014:
  - Пока реализовал на стороне Клиента в сценарии алгоритм. Завтра сделаю Серверную часть.
20.01.2014:
  - Все готово.
25.03.2014:
  - Скорректировать правильные английские названия. Common - общественный, публичный, а вот
  General - общий, общего характера. То есть IBaseObjectCommon => IBaseObjectGeneral
  и т.д.
27.03.2014:
  - Сформировать фронт работ для определения ServerCore.dll в качестве модуля. 
  Соответственно должен быть интерфейс для данного модуля.
  Вот одна из основных проблем: когда Клиент хочет вступить в бой - он отсылает
  запрос Slave. Тот в свою очередь транслирует этот запрос мастеру.
  Мастер принимает решение сгруппировать Клиентов. Существует два варианта развития событий: 
  1. Клиент переходит на другой Slave
  2. Клиент остается на том же Slave.
  В незавимости от варианта далее Slave передает событие создания группы разработчику и
  тот в свою очередь формирует на сервере группу для проведения боя (Комната, Сцена).
  Предположим один из клиентов не захочет дожидаться окончания боя и выйдет из MMO-группы.
  ММО движок исключит его из группы, а вот серверная реализация не должна этого делать.
  Серверная часть хранит образы Клиентов, по которым она можно сделать запись в БД или 
  оповестить о событиях. Потом клиент захочет зайти в новый бой. Его могут переместить на другой
  Slave или оставить на старом. Создаться новая ММО-группа и он попадет в новую Комнату на сервере.
  
  Физическая составляющая и БД должны быть представлены лишь интерфейсами (Фасад библиотеки).
  Так будет проще.
  Далее встает вопрос создавать ли отдельный модуль ServerLib?
21.04.2014:
  - Мастер оценивает безопасность сессии с Клиентом, а вот при коннекте Клиента со Slave - нет.
  Поэтому требуется доделать сценарии Авторизации Клиента и Перекоммутации Клиента с учетом
  этих правок.
  Также добавлена возможность проверки сессии SuperServer-ом и Мастером - 
  метод IsSessionSecurity перемещен из TMaster в TBaseServer.
14.06.2014:
  Убрал зависимость от Directx функций из ShareLib. Часть переписал сам, часть взял из исходников Wine.
11.07.2014:
  Разработка концепции ядра идет полным ходом. Исправил глюк в MMOEngine 
  (сценарий авторизации клиента при попытке соединиться с мастером отсылал пустой эхо пакет, 
  что противоречило системе поиска хака) и 
  MathTools (умножение матриц было напрямую через pOut, а нужно было через временную переменную).
14.07.2014:
  Придумал идею механизма "почкования". То есть можно будет обойтись без создания
  объекта модуля, а запросить экземпляр модуля у самого модуля.
  + virtual AdapaterBaseModule* NewExample() = 0;
  + virtual void DeleteExample(AdapaterBaseModule* ptr) = 0;
15.07.2014:
  Ядро пишется в AE. Основные механизмы описаны. Все вроде в норме. Надо еще
  описать как происходит запуск и работа ядра.
21.07.2014:
  Застрял на том как же должно выглядеть ядро. На самом деле надо смотреть и на то, что уже сделано, а не
  только что должно быть.Попробую сделать еще одну версию ядра и вставить в параллель со старым и методом 
  сравнения выявить чего там не хватает (применю так сказать инженерный подход).
23.07.2014:
  Придумал как избавиться от различий между Клиентом и Сервером в ядре. Теперь есть только одна сущность.
  Ядро имеет pure virtual методы и IDevTool.
  + virtual int AdapaterBaseModule::GetModuleID() = 0;
25.07.2014:
  Ядро новое готово, осталось проблему решить с Адаптерами. А именно: непонятно почему появляется 
  зависимость Графического движка от Камеры и GUI. Что, может быть, вполне логично.
  Но как это должно выглядеть в конечном итоге?
29.07.2014:
  NetTransport является вспомогательной частью MMOEngine. Сам TNetTransport должен находиться в модулях.
  А INetTransport - в адаптерах.
30.07.2014:
  Возникает проблема привязки к MyGUI: если из графического движка выкинуть поддержку
  MyGUI - разработчику придется переписывать все что он написал под другой GUI.
  Как способ решения этой проблемы (и не только этой, но и еще и Qt) - 
  дать разработчику реализовать интерфейс GUI для графического движка самостоятельно.
  Или как вариант указывать графическому движку какой GUI использовать.
31.07.2014:
  MMO и GE пока реализованы в виде полноценных движков. Но должно быть так:
  есть движок и есть реализация адаптера, использующего этот движок для реализации
  для разработчика.
  Думаю об интерфейсе адаптера для ММО.
01.08.2014:
  Prototype<----Adapter<>----Module
  Загрузкой ресурсов должно заниматься Ядро.
  Графика должна отображать, Физика просчитывать взаимодействия.
06.08.2014:
  Скомпилировал и запустил. Правда, все упало. Но это уже близко в финальному виду.
07.08.2014:
  Проверил Qt и MMO для серверов. Работает. Осталось проверить MMO для клиента, графику и MyGUI.
  MyGUI отрабатывает.
11.08.2014:
  В общем все работает. Далее - коррекция описания в EA ядра.
  Потом хочу написать статью в Хабрахабр.
  Думаю написать 2 статьи. О ММО движке и игровом движке.
  Все таки у меня больше гордости вызывает сетевой движок, там я 
  написал полную документацию, кроссплатформенность и большие возможности. 
  Сам же игровой движок у меня особо не вызывает восторгов.
15.08.2014:
  На сайте приняли только статью о ММО. Думаю дальше написать LoadSaveModel.dll, в котором
  будет загрузка моделей. Перенести из ядра и Share.dll.
  Далее AdapterGraphicEngine_OGRE.dll.
  Потом AdapterPhysicEngine_Bullet.dll.
19.08.2014:
  При таком подходе достичь главной цели - Игра, будет невозможно.
  Надо постепенно идти к плану Прототип-Адаптер-Модуль.
  Пускай пока будет прямой доступ к ОГРУ и Буллет у разработчика. Главное что делать с синхронизацией
  общих объектов (блин, вот почему я назвал IBaseObjectCommon).
  Это самая главная проблема над данный момент. Physic-Graphic-Sound синхронизация.
22.08.2014:
  Начал осваивать OGRE. Все для этого подготовлено. Ядро переделал.
  Mingun, спасибо за инвайт!

  Lair не прав на счет надежности ММО. Эта задача не ММО. За надежность должен отвечать кто-то другой.
  А именно - физически организованный кластер (например, пара компьютеров). Нельзя на одну сущность
  возлагать сразу несколько задач.

  Нашел недоработку. Если создать два объекта (например Slave и Client) в одном процессе,
  то статический объект в транспорте будет замещен и первый объект будет пользоваться
  транспортом второго. Исправил.

  Только сейчас начинается работа над движком. Связка OGRE c Bullet-ом. Многострадальное ядро,
  которое я уже 5-й раз правлю.
23.08.2014:
  Цель на данный момент - запуск клиента с окном MyGUI.
25.08.2014:
  DXUT умер. Да здравствует, DXUT! Запустил MyGUI, но пока только в одном потоке, правда.
  Осталось разобраться с ресурсами (настроить расположение, продумать названия папок).
  Выложусь на GitHub.
26.08.2014:
  Добавил функцию конвертации utf-8 -> cp1251.
  DemoKeeper из MyGUI совершенно не подходит.
29.08.2014:
  Думаю MD5(LP) заменить на Login, а SHA256(LP) заменить на Password.
  Это позволит избежать коллизий MD5 и SHA256.
  Тогда будет 
  Login(    ip, port,     subNet, pLogin, sizeLogin, pPassword, sizePassword)
  ConnectUp(ip, port, bp, subNet, pLogin, sizeLogin, pPassword, sizePassword)
  Теоретики хреновы. Их метод не подходит. Он не учитывает разделения на уровни:
  транспорт и сущность, знающая о БД.
02.09.2014:
  Тестил MMO, под Windows XP 1Гб - 156 соединений, а для Windows 7 8Гб - 1170 соединений.
	Отладил кучу багов.
17.09.2014:
  Реорганизовал файловую структуру проекта, теперь есть отдельная папка Resources.
  Сам проект содержит только исходный код, документацию и тесты.
24.09.2014:
  Почему-то под Ubuntu не всегда удается сделать TCP::bind(). 
  acceptor::set_option(reuse) не отрабатывает.
  Еще выяснилось, что происходит вызов Disactivate сценария, хотя активного сценария нет.
08.10.2014:
  Поправил глюк TConatinerRise, при вызове Realloc при старом размере равным нулю 
  не происходило выделение памяти.
  Задачи на октябрь: 
  1. Тест CMarkUp под Ubuntu.
  2. Сборка всего проекта под Ubuntu.
  3. Центр синхронизации OGRE-Bullet-OpenAL
17.11.2014:
  Тестил CMarkup под Ubuntu, все работает. Видимо, глючило только под МСВС.
        BD
    So  T  Ne
     Gr   Ph
05.12.2014:
  Добавил CallBackRegistrator без использования boost, только с помощью stl.
18.12.2014:
  Добавил Стресс тест ММО движка. Поймал баг: забыл unlock в Recv поставить перед return.
  Стресс тест - это постоянный процесс логина и выхода из системы клиента.
24.12.2014:
    Требования к графическому движку:
  1. Поддержка MyGUI.
  2. Загрузка скелетона.
  3. Манипуляции со скелетоном ( + возможность сериализации).
  4. Горячая и холодная загрузка моделей.
    Что выливается во вполне конкретные пункты:
  1. Загружаю модель танка из XML, вращаю башней в реальном времени (с помощью форм MyGUI),

04.01.2015:
  Возникла идея много-поточности ядра: с применением точки синхронизации, но для этого пришлось бы
  полностью переделать ядро и библиотеку разработчика. Думаю эта идея преждевременна.
  Сначало нужно доделать одно-поточную модель ядра. А потом переделать.
  Пока между делом доделаю SynchroPoint-SynchroAbonent.

21.01.2015:
  Пока начну с проекта /test/OGRE_Tech. Потом перенесу созданные файлы в Developer.
  Поначалу даже не знаю с чего начать. Должен быть класс, в котором можно будет добавить скелетон в сцену
  и менять параметры этого скелетона, удалить из сцены.
  Есть объект 1 уровня, он говорит какого типа: Add, Change, Remove.
  Внутри него храниться описание (2 уровень). Для Add структура дана полностью.
  Add:
    unsigned int mID_Object, unsigned int mID_Model, TObjectProperty mObjP, TModelProperty mModelP
  Change:
    unsigned int mID_Object,                         TObjectProperty mObjP, TModelProperty mModelP
  Remove:
    unsigned int mID_Object
  То есть вырисовывается 1 структура для первого уровня и 3 структуры для второго уровня.
  Также 2 структуры: описание игровых модели и объекта.

22.01.2015:
  TBaseGamePacket - базовый пакет в ShareDev.dll. Указывается ushort type, по нему определяется 
  тип пакета. Но это должно быть в Dev lib. В адаптаре графики создан интерфейс для 3 типов пакетов и доступа
  к OGRE.

02.02.2015:
  Начал описывать интерфейс графического движка. Для его реализации все есть: класс, в котором
  работает MyGUI (уже есть в примере работы самого MyGUI) и класс примера работы OGRE.
  Надо только их соединить, выкинуть события клавиатуры и мыши наружу (только те, что
  не были использованы GUI) и вуаля! Потом научиться добавлять и изменять характеристики объекта сцены.

07.02.2015:
  Проблема первая: как загружать ресурсы. В первом (MyGUI) и втором (pure OGRE) случае по-разному.
  Найти общее и вставить в класс GE.

  Библиотека разработчика загружает Resources.xml и далее, пробегаясь по всем адаптерам, настраивает 
  пути ресурсов.
08.02.2015:
  Работа адаптера: 1.Input, 2.Work, 3.Output.
  Многопоточный движок (обобщение):{Thread1 {Adapters},..., ThreadN {Adapters}}.
  GraphicEngine - единственный модуль, который имеет несколько частей - каждая
  отвечает за работу под разными операционными системами. Все остальные движки не
  требуется адаптировать под разные ОС.

22.02.2015:
  Пишется сам Грфический движок (надстройка), тестируется в OGRE_Tech. Все вполне удобно.
  Интерфейс я прописал, осталось проследить как будет выполняться конвейер GE.

06.03.2015:
  Для настройки конвейера ядра игры думаю использовать Conveyer.xml (задает DevTool)
09.03.2015:
  Доделал GE_Impl, но осталось сделать класс для удобного использования скелетона.
  Есть проблема: если создать форму MyGUI после создания GE_Impl, то позиция формы та, что была
  в дизайнере, но не в соответствии с выравниванием.
13.03.2015:
  Начал переделывать ядро под многопоточную модель.
  Есть потоки с модулями, а что делать с потоком ядра? Куда его девать? 
17.03.2015:
  Вчера второй раз ездил на машине. Пока на автодроме. Учусь играться сцеплением для лучшего контроля 
  скорости.
  Разхерачил библиотеку разработчика. Ядро я доделал. Осталось проверить как оно работает.
18.03.2015:
  Смотрел отзывы об MySQL, PostgreSQL. Положительных отзывов больше о PostgreSQL. Он поддерживает 
  больше стандартов, более надежен. Есть libpqxx и libpq++ для связи с БД с помощью C++.
21.03.2015:
  Только 9 модулей будут переопределяемыми (Активные модули): 
  ServerLogicSlave, ServerLogicMaster, ServerLogicSuperServer,
  PhysicEngineClient, PhysicEngineSlave, 
  AloneGUISlave, AloneGUIMaster, AloneGUISuperServer,
  GraphicEngine.

  Как общаются модули: id_sender - от какого модуля
                       type      - тип пакета модуля
                       sub_type  - тип пакета протокола разработчика для данного модуля
  Input(id_sender) id_sender == MMO
  HandleMMO(type) type == message
  HandleMessage(sup_type) sub_type == text_message или coord_object

  У Клиента должно быть ядро для управления модулями. От него уходят пакеты для конкретного
  модуля. Ядро зарегистрировано на получения событий ото всех компонентов. У Сервера точно так же.
  Протоколы взаимодействия Сервера с Клиентом так же находятся в Ядре.
22.03.2015:
  Под виндой обнаружилась одна неприятная особенность: объект-поток из области памяти игрового движка
  вызывает Work модуля (библиотека разработчика). Если будет 2 и более потоков, то процессор с двумя ядрами
  используется не на 100%, а на 50%, такое ощущение что есть дверь между движком и разработчиком и эти два потока
  пытаются втиснуться туда (войдя в область памяти разработчика, поток должен вернуться обратно). 
  Так как потоки молотят с малой нагрузкой в Work, то коллизии происходят постоянно. Одно из решений - нужно
  прописать прототип потока в движке и реализовать его в библиотеке разработчика.
  Решил забить на эту проблему, потому как: если Work внутри нагружена, то нагрузка поднимется до 100%.
  Видимо баг будет фичей, адаптивный характер движка. Как только используется больше
  кванта времени в Work, то процессор начинает использоваться на все 100%.
23.03.2015:
  Сделаю пакеты для работы с таймером. 3 пакета Start, Kill, TimeOut.
24.03.2015:
  Не сделаю. К центра(Логика) идут классические пакеты, к периферии идут указатели на TCallBackRegistrator
  для вызова методов из других потоков, но для этого нужно хранить указатели на модули в логике и 
  переделать пару TSynchroPoint+TSynchroAbonent.
  В описании конвейера для игрового движка нет теперь необходимости описывать кто кому пересылает события.
27.03.2015:
  Boost видите ли запрещает копирование сигналов! поэтому нельзя его использовать для копирования TCallBackRegistrator :(
28.02.2015:
  Доделал движок. Логика отправляет модулям адрес функций (через TCallBackRegistrator) для вызова из потока модуля.
  Вот как делать вызовы из формочек MyGUI?
02.04.2015:
  Вчера нашлась очень неприятная проблема на клиенте, точнее сетевом транспорте. Когда идет сценарий авторизации
  клиента в систему, по сценарию происходит разрыв соединения по инициативе мастера. Клиент пытается присоединиться 
  к Slave, но порт, с которого он соединяется другой (не тот что открыли). Этот порт выбирается из незанятых (58000-64000).
  НО если Slave будет отправлять клиенту пакеты по UDP, то клиент не получит пакет, потому что порт другой (тот что был при открытии).
  То есть есть два порта для TCP (59999) и UDP (1234). Slave получает информацию о порте TCP. Порт для UDP для Slave
  такой же. 
  Проблема еще в том что под Ubuntu нельзя открывать TCP_up позже чем Acceptor.
  Сделал так: в Disconnect TCP_Up.reset(NULL), а потом в Connect заново создал и открыл порт.
  Такое прокатывает под виндой, а вот под Ubuntu думаю не прокатит. Надо проверяться.

  Сделал так что и под Ubuntu все работает. Но надо проверить будет ли клиент принимать новые соединения
  (работает ли Acceptor).
03.04.2015:
  Клиент не смог принимать новые соединения. Решил эту проблему путем закрытия и удаления Acceptor-а.
  Далее заново открывать и настраивать TCP_Up, потом настроить Acceptor.
  Решил проблему транспорта, но теперь если произошло разъединение с верхстоящим транспортом, то на момент
  попытки соединиться транспорт теряет функцию приема соединений снизу. Интервал времени мал, но нужно это
  учитывать. То есть, если транспорт выступает в роли Клиента (только если повторно), то перестает быть сервером.

  Следующим этапом будет сборка под Ubuntu всего проекта.

18.04.2015:
  Баг: если в синхро-точке оставались пакеты, то при уничтожении игрового движка происходило падение,
  потому что пакеты были созданы в Dll разработчика, а т.к. Dll уничтожается когда движок прекращает
  работать, то и указатели на пакеты были мусорными. То есть нужно уничтожать синхро-точку
  до освобождения Dll.
21.04.2015:
  Если модуль не нагружен и отдает управление в поток тут же, то нагрузка на процессор всего ~50%,
  но если нагрузка есть (физика, графика), то КПД ~= 100%, поначалу это был баг, но я думаю скорее фича.
  Подстраиваемый под нагрузку движок.

03.05.2015:
  Все что писал про это баг - неправда. На самом деле это возникает из-за того, что в SynchroPoint
  у каждого списка есть мьютекс. Из-за этого и возникает блокировка потоков.
  
  Придумал какой-то интерфейс для физики. Думал, а что если физика закончила цикл работы, то как она
  сможет делиться с логикой результатами своей работы? Пакетами? Неее, не вариант. Все в пакет не засунешь,
  а если брать квант времени физики, то слишком долго. Можно сделать коллбэк функцию события окончания работы.
  Но тогда уж для всех модулей предусмотреть.
  
07.06.2015:
  Возникла проблемка: если у графического движка возникало событие закрытия окна, то это событие
  тут же уходило в игровой движок и происходило закрытие приложения. В логике происходила попытка освободить
  ресурсы, которые должны были быть освобождены графическим двжиком. Долго думал как решить эту проблему,
  и вот что вышло: дополнить те модули, что требуют освободить ресурсы (графика, физика(может быть?))
  CallBack функциями, вызываемыми в StopEvent.
21.06.2015:
  Начал дорабатывать XML формат игровой модели. Описал общую структуру (Version 0.5). Осталось описать свойства
  шарнира, соединяющего части между собой, и свойства физических тел. В общем задачи следующие:
  1. Узнать как описываются и какие свойства имеют шарниры (в понятиях Bullet это Constraint).
  2. Какие свойства имеют физические тела.
  3. Как загружать тела произвольной формы. В Bullet это ConvexHull Shape.
19.07.2015:
  Шарнир я описал, осталось описать форму физического тела. 
12.09.2015:
  Для обмена данными между потоками все готово. Добавил: методы CallBackModuleParam.
  Применяется: создаем данные для добавления объекта и указываем какую функцию вызвать и передать в 
  качестве параметра созданные данные. После вызова в потоке (например Граифики или Физики),
  созданные данные уничтожаются. Очередность создания/уничтожения/изменения для каждого
  компонента строгая. Поэтому коллизий не должно возникнуть. Единственное что может возникнуть:
  например Логика дала команду для создания объекта в Физику и Графику. До физики данная команда дошла раньше и
  объект создался. После создания прошло время и объект поменял свои координаты - нужно переслать информацию о координатах
  в Графику. Команда передается от Физики к Графике - а в Графики еще объекта нет. Поэтому либо Графика должно инициализировать
  процедуру обновления координат(это медленно), 
  либо Графика должна отложить команду о новых координатах и применить её потом(лучшее решение).

10.10.2015:
  Добавлен скрипт на lua для создания гибких и сложных пакетов. Также добавлены классы для удобного доступа.
  IMarkUpContainer, TMarkUpContainer и TBasePacket. Описание структуры пакета хранится в xml-файле.

  ВАЖНО! ИДЕЯ ИГРЫ СФОРМИРОВАНА. ЦЕЛЬ ИЗВЕСТНА - ИДЕМ ДО ПОСЛЕДНЕГО.
03.11.2015:
	Черновой вариант названия MetaMorf (Metamorfus). На работе есть тетрадь, в которой хранятся все записи
  по игре. Думаю, что должна быть она одна.
  Суть игры: существуют два режима в игре Classic и Evolution.
	Classic: в начале игры даются на выбор один из 4 танков: ИС-2(122 мм), Т-34-85, Panter(88 мм), KingTiger(105 мм).
  Игрок прокачивает постепенно все. В процессе прокачки открывается доступ к некоторым элементам следующего 
  этапа игры Evolution. 
	Evolution: в этом режиме возможно сконструировать танк собственной конструкции.
  Сначало выбираешь базу танка - его размер и ходовую часть (ее можно потом усилить, но это будет дороже).
  Далее нижняя часть каркаса. Компоновка частей - двигатель, трансмиссия, баки, расположение башни (ее может 
  и не быть, а может быть и 2-3), радио, БК и т.д. Потом рассаживаем членов экипажа. Чем больше серебра 
  отдашь, тем лучше компоненты (КПД двигателя выше, калибр и кол-во пушек больше и т.д.).
  Постепенно играя, зарабатываешь серебро и опыт для получения новых компонентов. Потом получаешь доступ к 
  изменению геометрии и составу сплавов. Керамика, композитные материалы. Слои материалов, динамическая броня, 
  дымовые шашки и т.д. Наращивать броню (падает удельная мощность). Возможность сбрасывать листы брони сразу 
  в бою. Скидывать башни и т.д.
	Система повреждений: существует HP у каждого танка. При попадании снарядом - снимается ХП в соответствии с 
  уроном снаряда. Но на сервере помечается зона вокруг пробития. При попадании в эту зону урон наносится в 
  размере 50%(?) от урона снаряда. Возможно поджигание масла и топлива в трансмиссии, баках. Подрыв БК. 
  Уничтожение членов экипажа. И т.д.
	Не нужно создавать 300-400 танков как у картошки. Все внимание уделяется компонентам 
  и изменению геометрии танка.
	Физика будет ближе к War Thunder. 
	
	Чем сложнее деталь, сложнее сплав, методы создания (сплав, штамповка, расскатка)- тем дороже её создание 
  и ремонт(10% от стоимости).  Поэтому будет какой-то баланс. Слишком крутой танк будет дороже в эксплуатации. 
  Сами же игроки и будут искать оптимальный вариант. Покупка слотов, т.о. можно будет создавать много
  конструкций. Полигон будет доступен в премиум аккаунте.
	Доступ характеризуется Классом (категория) игрока. Можно ввести звание.
  Балансить технику можно по стоимости компонентов. Хотя будет забавно, если очень дорогой танк
  будет откровенной шляпой и сдуется сразу. Но на это есть разум самого игрока.
  Получается, что игрок 10 уровня будет биться с игроком 1 уровня. Но танки у них буду стоить одинаково.
  Но у танка чуть-чуть какие-то детали будут другие (экономия на размерах).

  В Classic у танков есть своя цена, поэтому они могут конкурировать с определенным ценовым диапазоном.	
07.11.2015:  
  По поводу баланса: можно по желанию игрока менять настройки физики (легкий - как в картошке,
  сложный - как в War  Thunder). В соответствии со сложностью разный коэффициент серебра.
12.11.2015:
  Сделал форму-заготовку для редактора форм. Два дня потратил на то, чтобы понять как сделать Меню
  в MyGUI. 
18.11.2015:
  В BulletEngine есть implicit shapes (неявные формы - шар, куб и т.д.). Есть идея не хранить
  модели в виде набора точек, а в виде параметров. А потом восстанавливать в виде данных,
  которые "скушает" Bullet и Ogre.
21.11.2015:
  Впринципе вся картинка складывается. Какая часть модели учавствует в физике - решает объект.
22.11.2015:
  За премиум аккаунт давать возможность создавать свою собственную карту (один слот) и приглашать туда
  друзей. 
  За 5 побед подряд на сложном уровне физики давать плюшки - серебро, прем или золото (?).
24.11.2015:
  Давать имя танку при его создании. Имя - имя модели на сервере. 4 слота в начале игры.
  Далее новый слот - 100 золота. Единицы - "Золото" "Серебро" "Опыт" (опыт тратиться либо
  на прокачку экипажа, либо на прокачку 4 танков, доступ к деталям Эволюции и новым элементам
  карты). Конкурс на лучший танк -> купить формулу танка победителя конкурса. Конкурс на лучшую
  карту. Отправить видео заявку на конкурс. В этом видео показать бой.
  Кубок на лучший танк в ценовом диапазоне 100.000 серебра и т.д. Далее победитель получает
  золото. Танк становится доступным в магазине. Там описана история его победы(дата), автор и фото.
  1 раз в 3 месяца.
26.11.2015:
  Делаю FactoryGameItem. Работы много (скорее рутины доведения до красоты класса).
  Дня за 2-3 доделаю.
29.11.2015:
  Доделал загрузку Factory. Возникла другая проблема: я спроектировал формат Модели. но там нет места
  для гибкой ленты гусеницы танка. Как её реализовать непонятно.
  В Newton Physic есть пример с танком. Надо скачать последнюю версию и разобраться.
06.12.2015:
  В последней версии Newton нет танка. Но есть в какой-то из предыдущих.
  Проблема с разными моделями физики и использования/не использования графики на сервере и клиенте.
  Решается разными FactoryPattern для клиента и сервера. Таким образом поведение танка при создании будет разным.
  Вауля! И вся проблема в корне очень красиво решается.
  Физические движки бывают разные: Jiggle (малая Penetration error и быстрая обработка Constraint), 
  True Axis (почти то же самое что и Jiggle, только EULA), Bullet, Newton.
10.12.2015:
  Доделал сериализатор из XML в описание-структуру для создания геометрической формы.
24.12.2015:
  Доделал сериализатор из XML в описание-структуру для создания модели.
  Следующее: визуализировать с помощью OGRE Shape и Model.
27.12.2015:
  BuilderXXX_Ogre и BuilderXXX_Bullet - вот в чем вопрос.
28.12.2015:  
  Каждый объект владеет своей физикой. Объектами владеет сцена.
17.01.2016:
  EditorTerrain не нужен, потому что этим редактированием занимается EditorMap. Как таковой Terrain находится полностью в его 
  владении.
31.01.2016:
  Продумал структуру TMapItem, далее нужно сделать загрузку и сохранение в xml.
  Существуют звуки: 1. Описанные в сценарии, 2. Результат работы паттерна, 3. Прописанные в карте и 4. Те,
  что возникают в результате взаимодействия материалов, форм.
  Первые два формально можно сделать на данной базе понятий. Вторая существует только на словах,
  нет описания в данной системе понятий.
  Звук - файл зависит от: 1. Материалы, 2. Вид взаимодействия (трение, удар и т.д.), угол атаки,
  3. Скорость взаимодейтсвия, 4. Размеры форм. Это с т.з. классификации (наука).
01.02.2016:
  Таблица звуков является отдельным итэмом. Карта ссылается на какую-то таблицу.
  Внутри таблицы для каждой комбинации существует набор звуков и их параметров.
  Что бы на одну и ту же коллизию возникал разный звук из набора.
03.02.2016: 
  Достаточно лишь: масса, материал, скорость и угол атаки. Масса и материал - парные, поэтому
  их можно отзеркалить (повторить).
12.02.2016:
  Для TableSound map не подходит. Потому что например для одной и той же скорости 0 и 0
  могут быть разные углы, и ключ получается один и тот же.
13.02.2016:
  Доделал все итэмы. Но для полноты красоты движка не хватает: воды и травы (реализовать с помощью Зон?).
  
  Пока для игры данного набора итэмов достаточно. Потом можно нанять специалиста по Ogre и переделать
  конвейер графики, добавив туда эффектов графики (Блюр, лучи бога и т.д.).
  
  Визуализация: буду идти по двум напрвлениям. Сверху - анализ и синтез понятий (Сцена, комната, подвижные 
  и неподвижные объекты и т.д.) и снизу - сборщик геометрических форм Ogre и Bullet.
16.02.2016:
		ЭТАП СОЗДАНИЯ ИНСТРУМЕНТАРИЯ
  Условия достижения цели:
  1. Разделять объекты внутри Сцены по типу подвижности (оптимизация).
  2. Как делать сериализацию между сервером и клиентом (UDP - полная синхронизация, TCP - частичная).
  3. Загрузка карты в Сцене должна идти в нескольких модулях (а возможно и разных потоках,
  все зависит от кол-во ядер CPU), потому что нельзя данные графики загружать в другом потоке.
  Квантовать объекты карты на группы и давать потокам загрузки постепенно грузить их.
  
  Для данных работ выбор на "Объект игры (событийная модель)".
  Для физики предусмотреть понятие "Пауза". Во время загрузки вся физика находится в состоянии Пауза.
  
  Задача сцены: синхронизация объектов, выдать коллизии, выдать информацию по объектам,
  контроль за событиями внутри сцены.
22.02.2016:
  Клиент настраивает сцену и ставит на паузу физику в Комнате Клиента (TRoomClient). 
  Сервер же делает все то же самое в Комнате (класс TRoom).
  
  Вставил задание нагрузки процессора для MMOSlave (почему-то этого до сих не было сделано(???)).
  Более тонкая настройка физики для каждого мира - пауза, реальное время, контроль времени. 
  
  Для Клиента коллизия - звуковой и визуальный эффект (пока только есть таблица звуков,
  но визуальных - нет).
  
  Для Сервера коллизия - правила игры задают изменение физических показателей и 
  других параметров (например, ХП).
  
  Не раскрыто понятие TGameObject!
  
  Порядок реализации по Сцене (ВАЖНО):
  0. Понятие TGameObject.
  1. Загрузка, создание объектов.
  2. Отображение после загрузки (Show() ?).
  3. Синхронизация между Физикой и Графикой.
  4. Синхронизация (Update) между сценами.
28.02.2016:
  В рамках эксперимента проверить настройки Ubuntu для повышения открытых сокетов на один порт.
  Для этого поставил Ubuntu 14 server 64 bit.
  Далее
	sudo apt-get install xinit
	sudo apt-get install kubuntu-desktop
	sudo apt-get install kde-workspace-randr      - выбор разрешения экрана
	sudo apt-get install synaptic

  В synaptic установить: mc, gcc, qt4, boost, openSSL, 
  Максимальное кол-во 25000. Но если выключить клиент, но не выключать сервер, могут возникать 
  ошибки подключения при повторном запуске с 25000. 
  12-15 тысяч держит без вопросов (цикл выключать/включать). Может и 18-20 тысяч тоже, просто еще не пробовал.
05.03.2016:  
  Посмотреть для роутера таблицу маршрутиризации IP_out:port -> ip_inner:port, как настроить.
08.03.2016:
  Избавился от последнего наследия Тирады и МР. NetSystem (aka ns). Убогий сишный стиль. Переделал в класс.
13.03.2016:
  Суперское название. Все честно и по делу. Никакого Диснейленда, никаких розовых
  соплей. Длинно, но солидно (см. название игры).
17.03.2016:
  Делаю обвязку вокруг загрузчика карты.
  Кратко: есть построитель (Ogre, Bullet, OpenAL), ему на вход подается задача (Task).
  Task формируется посредством PreBuilder, для каждой задачи из MapItem он свой.
  Есть 7 типов игровых объектов. Каждый тип может формировать PreBuilder для своего типа сам.
  
  После обвязки остается дописать Builder_XXX.
  Потом делать синхронизацию физики с графикой.
23.03.2016:
  Вылизыаю интерфейс класса TBuilderGameMap.
  Интерфейс готов. Заполнить и создать недостающие классы (по Notes.eap->GameMap).
26.03.2016:
  Кроме сборщика карты/объекта нужен так же уничтожитель.
  Для него такая же схема - PreDestructor, TaskForDestruct_XXX, только кроме OpenAL - кешированный звук
  выгружать не надо. Выгрузка звука делается с помощью звукового движка.
29.03.2016:
  Пытался добавить вызов функции из потока Логики. Так нельзя делать.
  Сам же это задумал, сам же напоролся на это.
  Компоненты шлют в логику пакеты. Логика задает компонентам задание выполнить функцию из потоков компонента.
  
  Теперь, когда компоновка TBuilderGameMap готова, следует начать делать Task_XXX.
  Builder работает с интерфейсом Task, PreBuilder задает содержимое внутри Task.
  Task зависит от GameItem и той библиотеки с которой работает (Ogre, Bullet, OpenAL).
  1. Task_XXX.
  2. PreBuilder.
  3. Builder.
31.03.2016:
  Начнем с самого простого - графика Модели, Земли и Источник света.
  Самое сложное правильно натянуть текстуры на формы. Источник света это вообще самое простое.
02.04.2016:
  Поведенческий паттерн? PrototypeScene -> TScene.
04.04.2016:
  Потенциально можно менять налету (с сервера данные идут клиента) внутреннее состояние 
  даже Terrain, Light, etc. (Дает возможность место взрыва менять на углубление в Terrain).
  Но главная цель - смена состояния Model.
  У паттерна должен быть метод Get и Set - для обмена пакетов. Паттерн принадлежит TGameObject, но как
  будет менять состояние внутренних составляющих TGameObject? У клиента много потоков - физика, графика, звук.
  Формировать задания для каждого потока?
  Данное событие происходит достаточно редко (максимум 2-3 события в секунду для одного объекта).
  
  Pattern не нужен для Клиента! Он нужен только для Сервера. Pattern - игровой момент.
  Он описывает реакцию объекта на действия пользователя и объектов сцены. То есть Клиент синхронизирует
  физику с графикой и корректирует физику с данными от Сервера. Но корректировка все же требует
  Pattern для Клиента.
05.04.2016:
  Поломал TQueue2Thread со своими экспериментами. По сути бесполезный класс.
  Проблема многопоточного взаимодействия сводится к простой задаче:
  есть создатель данных и есть использующий результаты. Сколько бы потоков не было бы - 
  все можно свести к этим условиям. Если потоков N, то можно разбить на пары (как совбственно и делается
  в TSynchroPoint/TSynchroAbonent) и дать каждой паре для обмена объект. То есть существует только 
  два потока.
  В C++14/C++11 есть много вкусностей. Думаю перейти на Visual Studio 2015, но тогда не смогу писать на работе.
  Скачал с Хабра статьи об lock-free. Почитаю, подумаю. Пока консервация проекта.
06.04.2016
  Одна идея (потом консервация). Логика может собрать со всех объектов данные в один пакет, потом отдать в Графику, Физику
  и Звук. Таким образом можно избежать огромного кол-ва блокировок. Экономия составит 30-100 раз 
  (в зависимости от кол-ва объектов).
  
  Вполне реально избавиться в TListMultiThread от мьютекса. Но там есть косяк с указателями.
  Их надо будет сделать или volatile или atomic. Но тогда нужно будет переименовать класс в
  TList2Thread. LatencyRemove, а вызов Remove - пометить флагом, что нужно удалить.
  Добавляющий поток по флагу удалит его позже. Нужен ли Below?
07.04.2016:
  Консервация продлилась 2 дня. TDataExchange2Thread лишён мьютекса! Только volatile (atomic для C++11).
  При взаимодействии потоков используется TSynchroPoint. Если только 2 потока, 
  то можно использовать TDataExchange2Thread.
08.04.2016:
  Тест скорости TDataExchange2Thread (микросекунды на операцию добавления):
  Windows XP 32 bit Intel Core 2 Duo E6600
             BOOST            volatile         без volatile
  Release:   0.70              0.61              0.63
  Debug:     3.08              1.54              1.54
10.04.2016:
  Нужен белый IP. 
  В Internet точно есть технологии создания Сервера в "домашних условиях".
  Скорее всего нужно будет звонить в Рустелеком.
  
  Сейчас нарисую граф сценариев для процесса игры Клиента и Сервера, чтобы понять для чего нужен
  игровой объект.
  
  Описываю сценарии игрового процесса Клиента и Сервера (Slave). Этап Достаточности.
  
  Рустелеком за даром и очень быстро дал белый IP.
11.04.2016:
  Провел чистку, GCS->Mutex, убрал TD_WINDOWS. Теперь надо собраться под Ubuntu и протестировать.
24.04.2016:
  Все-таки идея выбора игроком уровня сложности еще выстрелит. Тот, кто проиграет даже на сложном уровне,
  получит серебра все равно больше того, кто выиграет на легком уровне. Но при условии, что он хоть что-то делал.
  Фраг, попадания, засвет, активность в виде пройденого пути и т.д.
  Уровень сложности - аркадный или реалистичный. И не будет этого постоянного нытья про баланс. Все в выигрыше.
  Причем в одном бою могут играть с разными уровнями сложности.
  
  JusticeBalance - система балансировки. Именно должно существовать название для ассоциации с самой игрой.
  Существует еще балансировка частей танка - по цене и ремонту. Но это уже другая история.
26.04.2016:
  В очередной раз пытался "вылизать" код MMOEngine. Пытался докапаться до безопасности каналов при Авторизации и Перекомутации.
  При Авторизации Slave создает событие ConnectDown и в нем содержится MITM информация о канале. Чтобы проверить
  нужно считать из БД Логин, пароль и проверить надежность канала.
  При перекомутации проверять канал не нужно.
28.04.2016:
	Есть одна особенность использования перекоммутации (RCM).
	Всегда инициатором RCM является Клиент. И вот почему и как это происходит.
	Клиент отправил запрос Slave на вход в бой. С этого момента Клиента может отправить Slave только
	запрос на выход из ожидания Боя. Slave теперь уже не может отправлять пакеты Клиенту, потому что
	не знает когда начнется RCM (и начнется ли вообще). А если начнется, то пакеты для Клиента просто пропадут.
	Когда группа сформирована Slave получается событие RestoreContext (но это только если произошла смена Slave).
	Если смена Slave не произошла, то FindSlaveSessionByGroup() - отправить данному Slave список Клиентов 
	(отправлять независимо от того, произошло ли RCM). Slave сам проверяет наличие Клиентов у себя и начинает Бой.
20.05.2016:
  Основная проблема сейчас - большая нагрузка на работе. Не хватает сил и времени для проектирования GameProcess.
  Нужна ясная голова для такого рода деятельности. Для написания кода много ума не надо - сиди и вбивай его.
  Правлю саму структуру GameProcess дело от дела.
23.05.2016: - Начинаная отсюда Черновые записи - возможно эти идеи тупиковые
  Для Клиента: в главный поток (MainThread) поступают события от других потоков. 
  MainThread дает задания для выполнения в конце выполнения потока EndEvent(). 
  Задания зависят от Текущего сценария. Текущим сценарием владеет MainThread.
  От того какие события поступают от второстепенных потоков зависит выбор нового сценария.
  На Сервере Сценарии могут чередоваться, то есть не нужно событие снаружи (там только один поток).
    HandlerScenarioGameProcess, ScenarioGameProcess.
  Например: идет синхронизация Графики по результату работы Физики. Тут приходит пакет от Сервера о новых
  координатах, ориентации и внутренним свойствам объектов на карте. Значит нужно скорректировать Физику.
  Процесс синхронизации Графики как шел, так и идет. Эти сценарии не пересекутся(???).
  
  Проектирование GameProcess имеет одну из целей - продумать структуру GameObject.
24.05.2016:
  Для Клиента есть 3 слоя сценариев - Графический, Физический и Звуковой. Для каждого слоя существует свой текущий Сценарий.
  У Сервера 3 типа сценарных плана (ну соответственно Slave, Master, SuperServer).
25.05.2016:
  Вместо слоя лучше подходит понятие Агрегация Сценариев. GP_AggregateScenario, GP_Scenario_XXX.
26.05.2016:
  Пока слишком много абстрактных идей. Непонятно даже с чего начинать, нужно больше конкретики - 
  и для того, чтобы понять правильно ли я выбрал направление, и для того, чтобы вспомнить куда я шел 
  (для этого нужно прошерстить написанный код Builder/Destructor ).
  Инициатором всегда выступает Logic. Начало ли это загрузки карты, пришли пакеты от Сервера ( Сервер - частный случай,
  ведь данные могут придти от Реплея или самого Клиента).
  GP_HandlerScenario_Client находится в Логике
28.05.2016: ВАЖНО!
  Вот результат умственных страданий: поток Логики с помощью списка для обмена пакетов (Труба) отправляет Задания для 
  потоков Физики, Графики и Звука (ФГЗ). Причем объект этого класса отправляет самому себе. Модуль Логика перенаправляет
  управление от WorkEnd потоков ФГЗ и там происходит разбор пакетов. ФГЗ в свою очередь, когда это критично,
  может отправить событие перехода из одного сценария в другой (например, началась загрузка Карты и надо дождаться пока все
  потоки начнут загрузку и когда загрузка закончится). Физика после расчетов должна собрать пакет, описывающий 
  подвижные объекты или объекты изменившие свои свойства (игровой момент), и отправить его Графике и Звуку. И так
  каждый цикл. Также Физика отдает управлению объекту (GP_HandlerThread_Physic), который анализирует коллизии 
  с точки зрения Игры (то есть это должен быть полуабстрактный класс, полностью реализованный в DeveloperDLL). 
  Этот объект может менять свойства объекта и накапливать какую-то статистику, влияющую на его состояние (например,
  ХП у танка и т.д.). Но это больше характерно для Сервера. Клиентский GP_HandlerThread_Physic выполняет малую роль.
  Но пускай он будет. Также есть GP_HandlerThread_Graphics - отправка событий на Сервер - нажата кнопка В бой или
  клавиша W (вперед) и т.д.
  Особенности протокола GP_AggregationScenario_Client - для отправки пакетов от Физики - Графике и Звуку:
  избегать операцию new - использовать повторно пакеты с флагом, который описывает использовали ли его 
  в Графике и Звуке. В принципе проблема решаема. Но вот надо понять можно ли сделать пакет фиксированной длины.
  ID, position, orientation - const длина. А вот что такое InternalState - можно ли его зафиксировать?
  Логика отправляет на Графику и Звук какие эффекты воспроизвести. А Физика для Звука - скорость, позицию и ореинтацию,
  и также события коллизий. Для Графики - скорость, позицию и ореинтацию, также события коллизий и InternalState.
01.06.2016:
  Основные проблемы:
  1. Минимизация задержки при возникновении события клавиатуры и мыши и отправка их через ММО на сервер.
  (требует решения по ходу реализации, некритично).
  2. Оптимизация обмена пакетами между Физикой с Графикой и Звуком, чтобы реже использовать оператор new. 
  Решение: на каждый объект игры заводится очередь отправленных(volatile bool flgAppliedInGraphic, 
  можно ли использовать повторно) и зарезерованных пакетов. Эти очереди хранятся в 
  GP_HandlerThread_Physic как map_id_list.
  3. Структура пакета при обмене Физики с Графикой и Звуком: ID,pos,orient,InternalState. Так вот, что 
  такое InternalState в понятиях этого обмена? Важная проблема. По сути это id_subject,pos,orient.
  id_subject - идентификатор субъекта в GameObject, но id_subject должен совпадать в ФГЗ.
02.06.2016:
  Решение 3 проблемы: паттерн поведения определяет что отдать Физике от Физики (Сервер-Клиент, Реплей-Клиент и 
  т.д.), от Физики к Графике и Звуку. Есть базовый пакет + пакет адресуемый одинаковому паттерну
  (на Сервере это один объект отправляет Клиенту, в Клиенте (реплей,синхронизация физики) один и тот же объект
  отправляет сам себе). По сути базовый пакет - игровой процесс, доплнительный - часть Конкретной игры.
  Например, мощность двигателя - дополнительный; ID, pos, rotation, список субъектов (вместо имени можно
  использовать unsigned char id), паттерн сам себя поймет, по сути базовый паттерн может формировать свой собственный
  пакет, и движку все равно что передавать.
  Все же напрямую игровой объект не должен передавать пакеты, должен быть посредник. Во-первых это можно использовать
  для оптимизации при использовании этих пакетов на Графике (если камера слишком далеко, то пакет можно не применять),
  во-вторых все равно при передаче используется ММО, а это уже внешний объект.
  Решение второй проблемы тогда слегка меняется. TContainerRise используется в двух случаях: 
  1. Сервер-Клиент, серверный паттерн отдает указатель на свой TContainerRise с пакетом, 
  2. Клиент-Клиент, набор из TContainerRise.
14.06.2016:
  Интересная идея от Шухрата: хранить игровые параметры в отдельной БД. Параметры используются для чтения.
  Читают только Slave-ы для пересылки Клиентам и использования в процессе игры. Удобно менять. Сама БД получается
  ненагруженной. Игровые параметры: мощность двигателя, пробитие снаряда, скорость поворота и т.д.
15.06.2016:
  Пришло время описать Протокол Client-Slave.
  Уровни для пакетов - Game, GameImpl.
19.06.2016:
  Пакеты обрабатываются в PCS_HandlerXXX.
  Пакет для ePacket_CorrectGameObjects на Slave формирует Developer, потому что возможно требуется
  знать какие объекты Клиент должен обновить, а про какие он знать не должен.
22.06.2016:
  ВАЖНО!
  Задачи Паттерна: 1. Сериализация физической модели (Сервер->Клиент, Реплей и т.д.).
  2. Визуализация физической модели на Клиенте.
  3. Реакция Паттерна на изменение параметров Графическими и Звуковыми эффектами.
  1. Паттерн создаёт пакет, который описывает его для воспроизведения на другом объекте
  того же класс - сериализация. Для этого Паттерн Игрового объекта опрашивает все Паттерны, 
  которые отвечают за модели, входящие в состав Модели Игрового объекта. Так по итерации вниз для всех
  моделей, входящих в состав других моделей. Значит Игровой объект должен хранить Иерархию Модель-Паттерн.
  По сути 2 и 3 задачи имеют одно и то же события для начала в реализации. Физика передает пакет Графике и Звуку,
  причем это происходит в одном объекте, но в разных потоках.
26.06.2016:
  По-умолчанию используется Паттерн для каждого типа объекта из ShareDev, 
  только как узнать какой использовать? 
  Modify -> InternalState от одного объекта к другому - ???
  Например для Terrain на Сервере или через инструментарий для редактирования карты.
29.06.2016:
  Разделение модели, слияние моделей и форм, модификация модели.Задать возможность.
30.06.2016:
  В задачи Паттерна также теперь входит обмен данными для Модификации GameObject и 
  применение данных из FGI в случае модификации так, чтобы InternalState не менялся.
01.07.2016:
  Обнаружил косяк TBreakPacket, точнее особенность использования в циклах.
  Стековый объект, помещенный в TBreakPacket, не копируется, а значит в следующем цикле
  имеет другое значение. Решение: функции PushBack и PushFront дополнить флагом bool copyData,
  если требуется скопировать данные внутрь bp.
  Требуется связать понятие Паттерн, Сцена и Агрегация Сценариев в одну схему.
  Но для этого надо продолжить цепь требований от InterpretatorGameImpl.
07.07.2016:
  Идея для карты: Выбор: 
    Стандартная(те что в списке Сервера), 
    Оценка новых карт игроков, 
    Только топовые карты игроков,
    Случайный выбор карты игроков.
  Рейтинг карты складывается из статистики (ее оценивает сервер) и оценке, которую ставят игроки.
  Причем если игрок ставит оценку новой карте, то игроку дается больше серебра с учетом коэффициента.
  Для старых карт коэффициент оценки ниже. Т.о. выгоднее оценивать новые карты. Если карта набирает очень много низких
  оценок, то она выкидывается из списка.
  Игрок покупает новую карту - 1000 золота. Измения в карте - за серебро. Хочет выложить на Сервер - 500 золота.
  Если карта имеет высокий рейтинг - игроку дают серебро. Если карта очень высоко оценивается - даже золото.
  Если игрок хочет сделать копию со своей карты - 1500 золота. Копия с чужой карты - 3000 золота.
  Есть слоты под карту. Карту можно удалить. Если карта выбирается и становится Стандартной, то игроку дают 
  золото и Карта содержит в описании имя автора и т.д. (то есть слава и гордость для игрока - "волшебная кнопка" в действии :) ).
  Копию со стандартной карты тоже можно делать - 4500 золота.
  Игрок покупает слот под карту за золото. Называет её как-то. Входит в режим редактирования. 
  За серебро расставляет здания, деревья, кусты, меняет ландшавт. Решает сохранить. Выкладывает на сервер.
  Сервер, прежде чем принять карту, анализирует карту на адекватность (нужен алгоритм).
  Карта попадает в реестр карт игроков. Копия - это новая карта. Если игрок сделает изменения 
  в карте, которую уже выложил на сервер, и захочет выложить еще раз (будет стоить дешевле, 
  с каждым выкладыванием еще меньше), то карта в реестре заменяется, её рейтинг сбрасывается и она опять становится новой
  для сервера. Так же можно отдавать карты на конкурс Карт. Но это дороже - 10000 золота. В случае выигрыша - золото,
  но все зависит от рейтинг. Когда карта выиграет и её рейтинг: 10/10  - 100000 золота, 5/10 - серебро, 1/10 - ничего.
  
  Для техники схема похожа. Игрок создает свою технику. Любой игрок может сделать копию при 
  просмотре статистики другого игрока - 2000 золота. Сделав копию, технику можно менять.
  Таким образом, вся техника и карты полностью создают игроки. Сервер же только контролирует правила игры и служит
  собственно самим сервером.
09.07.2016:
  Клиентская комната (Room) обрабатывает коллизии Сцены для реакции в виде Графических и Звуковых эффектов.
10.07.2016:
  После анализа, GP_AggregationScenarioClient - сам оценит ситуацию и примет решение по накоплению пакетов синхронизации
  в случае начала загрузки карты в Бою (будет копить). Пакет окончания загрузки карты таким образом не нужен.
13.07.2016:
  Пришла в голову идея карты. В начале одна из команд разделена (допустим это команда А). 
  Если команда Б захочет уничтожить одну из групп разделенной команды А, то есть вероятность того, 
  что вторая группа команды А может зайти в тыл. Возникает интрига, идти ли в атаку команде Б.
  Потому что вторая группа может и стормозить. То есть требуется организованная атака, но и это может
  не спасти. "Тревожная карта". Карта большая 3000х3000 метров.
  Второе: если создавать роты, то почему бы не создать 3 команды? 10 против 10+10. Две другие также будут биться
  против 20. Месиво из команд. Причем карта маленькая 600х600 метров. Ники врагов надо скрыть, что бы не было 
  договорных игр.
14.07.2016:
  Идея от Шухрата: анимация солдат, ремонтирующих слетевшую гусеницу.
22.07.2016:
  Внутренняя синхронизация паттерна. Физика внутри паттерна, получив квант от Сцены направляет по трубе
  графике и звуку события для синхронизации.
  Потом можно начать делать загрузку. Далее внешнюю синхронизацию. Внешняя происходит по кванту от потока
  логики. Это значит, что пришел пакет от Сервера и требуется его применить к физике.Возможно, что-то 
  пришло для графики и звука.
//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------

Проблемы, связанные с GameProcess: 
1. Передача данных от Физики на Графику и Звук с минимум использования new.
2. Минимизация задержек между получением от Графики событий мыши и клавиатуры до отправки через ММО.
3. Раскрытие понятия InternalState при обмене между Физикой и Графикой (Звуком ?).

3) TBuilderMeshOgre, TBuilderMeshBullet -
4) TBuilderTerrainOgre, TBuilderTerrainBullet - 
5) Следующий этап - написание игры и коммерциализация (Private account on Github.com) -
//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------
    INFO
1). Вода на танке. При выезде из воды, она стекает с корпуса. При движении по суше и воде, вода вылетает по радиальной траектории с траков.
2). Easter eggs. Пасхальные яйца: строй фрицев (советских) стоит перед командиром. При подъезде к нему танка, отряд либо разбегается(слышно как говорят, кричат), либо исчезает из виду. Появляется в начале битвы среди строений.
3). Реализм световых лучей в лесу. Инфо: возникает из-за оседающей пыли. При проезде по траве пыль поднимается вверх.
4). Грязь. Комки грязи на корпусе. Поведение похоже на воду, но грязь оставляет след на танке после высыхания (может поменять цвет).
5). Эффект шероховатости поверхности. У разных танков разная технология  создания брони. Для литой характерна шероховатость, для катанной такого эффекта нет. Для катанной - блеск металла.
6). Очень нравится как танки двигаются в War Thunder! Вот если взять эту фишку и совместить с процессом игры WoT - будет вообще супер.
Когда управляешь танком в War Thunder - получаешь настоящее удовольствие. Но вот сам геймплей полный отстой.
WT - чувствуется МАССА танка, его тяжесть. А в WoT - как будто танки пластмассовые, ничего общего с реализмом.

//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------
            Название игры - "Evolution of war machines". Компании - "Only C++ Company"
            Power metal
//----------------------------------------------------------------------------------------------------------------
    BUG:

  Парадигма
  
  1. Дублирование данных и кода - зло.
  2. Многозадачность для программиста - зло.
  3. Если пишешь код для других программистов, то пиши кроссплатформенный.
  4. Код должен быть по возможности общим. Формализовать группу классов, искать общие черты и свойства.
  Лучше написать и исправить 5%, а не 100%. 
  При этом одно действие порождает множество воздействий(когда код общий),
  и, наоборот, приходится делать много действий для одного воздействия.
  5. Количество базовых классов и файлов должно быть минимально. Но в то же время
  они должны порождать множество возможностей.
  6. Не старайся писать общий код. Хотя это и противоречие. Это инженерное искусство.
  Лавировать, тогда, когда нужно писать общий, когда частный. Тут надо думать.
  7. Один класс - одно поведение, один объект - одна задача.
