/*
Author: Gudakov Ramil Sergeevich a.k.a. Gauss 
Гудаков Рамиль Сергеевич 
Contacts: [ramil2085@mail.ru, ramil2085@gmail.com]
See for more information License.h.
*/

#ifndef DateChangesH
#define DateChangesH

// дата создания 1.12.2011

//***
//по архитектуре см. ./doc/архитектура.doc
//***

/*
    DONE
    TODO
    INFO
    BUG
*/


/* 
    DONE: 

21.12.2011:
 - TList. Список с блокировкой, для операций над элементами из разных потоков.
 - отладка транспорта.
25.12.2011:
 - первый ответ от сервера.
 - произошел коннект между клиентом и сервером.
 - логирование и отладка транспорта.
26.12.2011:
 - версия при попытке соединиться.
27.12.2011:
 - транспорт контроль свежести пакета.
 - механизм дисконнекта.
28.12.2011:
 - асинхронный вызов списка клиентов в окне сервера.
30.12.2011:
 - Сервер: список клиентов перевести в TArrayObject для повышения скорости.
 - свежесть пакета при потере соединения synchro.
 - два типа CN - стрим и пакетный в транспорте.
06.01.2012:
 - уведомление о приеме Stream и Packet.
07.01.2012:
 - контроль соединения - разрыв на клиенте и сервере, 
 - клиент: разрыв по 1. отсутствию пакетов от сервера 3 секунда и 2.по событию Disconnect от транспорта.
 - сервер: разрыв по отсутствию пакетов от клиента 1 минута -> 1.событие Disconnect от транспорта. Всегда отсылка раз в минуту Эхо.
 - Стрим для гаража.
 - время для массива клиентов сервера: отсылка и прием. раз в минуту отсылка Эхо.
 
10.01.2012:
 - отладка транспорта
 - добавлено управление клиентом с помощью скрипта.
 - лог стрима.
 - лог клиента по нику.
11.01.2012:
 - тестирование транспорта с 220 клиентами.+
 - тестирование транспорта с 450 клиентами.+

13.01.2012:
 - Блин, разрушил транспорт :(. Неувязки с многопоточностью.
   Разобрался: Клиент отправляет по неизвестному транспорту адресу, но не получит от НЕИЗВЕСТНОГО.
               Сервер наоборот: отправит по известному, но получит от неизвестного.
               Поэтому не возникнет ситуации когда будет добавление из двух потоков.
               НО 

14.01.2012:
 - Лог транспорта, события.
 - Список ожидающих отправления и список ожидающих подтверждения mArrWaitSend и mArrWaitCheck.
 - Очередь на отправку у транспорта.
15.01.2012:
 - отладка: вывод в файл процента нагрузки главного потока сервера.
16.01.2012:
 - Загрузка списка танков в гараже.
17.01.2012:
 - Выбор танка в гараже.
18.01.2012:
 - Форма ожидания боя и запрос на бой.
 - Запрос на бой обработан и сформирована команда.
 - Зачатки балансера.
19.01.2012:
 - Стрим для начала боя
21.01.2012:
 - Думаю над зонами и картами, физикой и боем. Это все надо как-то увязать.
25.01.2012:
 - Обратный отсчет перед боем на сервере.
 - Обратный отсчет перед боем на клиенте.
12.04.2012:
 - DXUT + DirectX + Qt4
14.04.2012:
 - Начал реализацию архитектуры на основе DirectX
15.04.2012:
 - Симбиоз DirectX и Qt4 для графики - там все просто TBaseDirectX с функциями отрисовки и событий.
17.04.2012:
 - Переделываю протокол общения Клиент-Сервер с учетом графа сценария поведения. Я думаю это дня на 2-3.
 - Установка Git. Это предложение тест для него. Пока работает. Но муть полная. Думаю, можно привыкнуть.
18.04.2012:
 - Корректирующий пакет отправляется группой не более 5-10 событий в пакете. Пакеты помещаются в TransportMain
 в независимости от кол-ва пакетов.
 - Придумал как будут взаимодействовать потоки DX и Transport Main при обмене корректирующих пакетов и стрима.
 Будут меняться непосредственно параметры объектов MultiThreadQueue. - 
19.04.2012:
 - Проверка ClientMain +
 - Проверка GameRoomPrepare +
 - Проверка WaitForm +
20.04.2012:
 - Появился ManagerGUI. Он управляет окнами клиента. Также управляет загрузкой компонентов для проведения боя и обрабатывает ответы от сервера.
21.04.2012:
 - Вставить время в Queue.
22.04.2012:
 - Мучаюсь с TA_In_Fight. Разная длина sNick и cnt Tank.
28.04.2012:
 - Реализовал TA_In_Fight. Этот класс готов для масштабирования.
01.05.2012:
 - Отдыхал. Не мог даже смотреть на проект. Похоже, что на работе рабочее место лучше. Определенно лучше.
02.05.2012:
 - Угу, лучше.
03.05.2012:
 - Логирование DirectX.
 - Кольцо работает. DirectX и транспорт обмениваются данными.
 - Подвод данных к комнате.
 - Отсылка запроса корректирующего пакета.
05.05.2012:
 - Доработка TRoom.
09.05.2012:
 - Доделал транспорт(все тесты проходит). Думаю над графикой.
10.05.2012:
 - Обнаружил странный глюк в Студии: иногда сервер может падать из-за того что 
 CRT обнаруживает запись в память после закрытия сервера. В ~TGarage().
 Помогает ребилд проекта.
11.05.2012:
 - Работа над ModelDX, ManagerModelDX.
14.05.2012:
 - Добавлен EditorModel.
17.05.2012:
 - Работа над Editor. Загрузка данных из ini-файлов.
18.05.2012:
 - Заработал графический движок. Нарисовал первый объект :)
21.05.2012:
 - Вчера скачал программку для конвертации из primitives в x формат.
  Загрузчик надо переделать под этот формат. Теперь надо нарисовать хотя бы танк.
  3D Object Converter
  Конвертируем из primitives в *.obj (WaveFront). Далее используем для помещения в Mesh класс
  Порядок действий при конвертации:
  1. Загрузка модели.
  2. Options->Export->WaveFront поставить галочку Export Vertex Normals
  3. Tools->Flip Scene UV Map Vertically.
  4. Save as WaveFront.
  5. Подправить *.mtl и привести примерно к такому виду: 
                newmtl Material_1
                Ka 0.4 0.4 0.4
                Kd 0.587609 0.587609 0.587609
                Ks 0.171744 0.171744 0.171744
                illum 5
                Ns 8.000000
                map_Kd PzVl_Tiger_I.dds
 - Консервация проекта. 
11.06.2012:
 - Добавлен SelfTank, думаю о изменении интерфейса класса ManagerDirectX.
14.06.2012:
 - Проект под лицензией GPL.
 - Melissa - транспорт, BigJack - графика, Robert - физика, Клиент(GUI) -- для лучшего понимания архитектуры
 - Основное положение для протокола: сервер на прикладном уровне управляет Клиентом и BigJack.
Т.о. это как бы два прикладных протокола.
05.07.2012:
 - Добавлена возможность Qt + DirectX Qt4.5.0.
 - Консервация проекта с веткой на основе DXUT. Развитие ветки Qt+DX.
19.07.2012:
 - Консервация. Серьезные архитектурные изменения. Приводится в порядок модульная структура проекта.
ITBaseObject, TanksLib.lib, TManagerGUI, TBaseGUI_DX.
 - Нашел простые редакторы моделей OBJ. По идее EditorModel пока не нужен.
07.08.2012:
 - Общая архитектура в Enterprise Architect.
08.08.2012:
 - Оживил Клиента и Сервер. С новой архитектурой. (doc/Общая архитектура.EAP)
 - Версия v0.040
15.08.2012:
 - Почти запустил BigJack. Осталось доделать IBaseObjectDX::SetModel - установить матрицы.
20.08.2012:
 - Улучшил TCallbackRegistrator, добавил std::set<...>.
29.08.2012:
 - Перешел на DXUT. Теперь поток Qt работает в DXUT.
 - BigJack заработал. Дело было в том, что Subset в DrawSubset был равен 0, а должен быть равен 1.
30.08.2012:
 - Перешел с формата *.obj на *.bj, убрал лишнюю загрузку текстур и компиляцию шейдеров и снизил время загрузки
 с 5 секунд до 73 мс. *.bj - бинарный формат хранения Mesh. BigJack формат.
31.08.2012:
 - Разбираюсь с матрицами. Думаю как сделать привязку частей модели друг к другу по-умолчанию.
03.09.2012:
 - ЛОЛ в WOT XZ находятся внизу, а Y это стрелка уходит вдаль.
10.09.2012:
 - Анимация: разделение объектов на чисто анимированные и "грязно".
16.09.2012:
 - Болею,  голова вообще не соображает. Потом Tree доделаю.
 - Модели в ВОТ зеркальные.
20.09.2012:
 - Умею вращать башней и двигать пушкой у танка.
27.09.2012:
 - Добавлена поддержка XML формата. Чтение, запись. Через CMarkup.
 - Перенаправил поток событий на Qt от DXUT.
01.10.2012:
 - Сделал Менеджер ресурсов. Осталось Довести до ума шейдерный стек и камеру. И движок будет закончен.
02.10.2012:
 - Добавлено отображение фпс.
04.10.2012:
 - Пытался научить движок делать объекты прозрачными. Не получилось сразу.Дело в том, что 
 прозрачность разных объектов определяется порядком их построения. Рендер прозрачных нужно
 производить в самую последнюю очередь. Причем кол-во прозрачных объектов в движке
 ограничено (если больше выглядит не очень красиво). Проблема решается сортировкой по расстоянию от камеры.
 Но данная проблема не критична. Если понадобится - решу в будущем.
31.10.2012:
 - Переделка архитектуры. Идея: События генерирует Qt класс (точнее происходит перехват WinApi 
 и отсылка в Qt обработчик, далее событие обрабатывается ManagerEvent). Т.о. стало возможным 
 перехватывать и GUI события. В общем достаточно пронаследоваться не от Qt, а, например, от другого GUI.

05.11.2012:
 - Возникла идея по симбиозу Qt и DirectX. Суть идеи (всего две, надо определить ту что быстрее):
 1. Берем буфер из DXUT вставляем его в QImage и отдаем на QWidget. Далее рендерим GUI с параметрами Alpha. - так думаю что будет медленнее.
 2. Рендерим элементы GUI и отдаем в DXUT. Там средствами DirectX происходит альфа-смешивание и окончательный рендер.
 Время выполнения:

06.11.2012:
 - Qt+DXUT = R.I.P.
 Время на выполнение слишком велико. На WinXP 30 мс, а на Win7 200 мс (!!!). Но это для первого способа.
 Есть второй способ. Но это не исправит ситуации. Конвертации Qt->DXUT и наоборот слишком медленны.
 Виден только один  способ - DXUT Native GUI. Но прежде надо продумать архитектуру с учетом источников
 событий. NET, GUI, LoadFromHDD, Key+Mouse и т.д. Есть модуль управления(МУ) движком игры. Он имеет определеный интерфейс,
 МУ берет настройки для конвертации внешних событий из файла в зависимости от внешнего воздействия. Надо проанализировать
 схему работы с DGUI, подумать над интерфейсом МУ и связи с MOC. Но завтра надо доделать ОПП.
08.11.2012:
 - Для всех классов GUI DXUT сделать виртуальным деструктор. 
 - Разобраться с технологией GUI DXUT.
12.11.2012:
 - Была идея создания TankLib(классы, которые характерны для игры танки), но считаю в этом необходимости нет.
В идеале все пишется на Python и "превращается" в С++ классы в менеджере Компонентов.
Но пока я не освоил эту технологию, буду все классы держать в GameLib 
(например, TMakerObject, метод NewByID_Behavior()). Потом уберу оттуда в Python.
21.11.2012:
 - Нафиг Python. Пишется DLL. У нее три функции GetClientDeveloperTool(),
GetServerDeveloperTool() и Done(IDeveloperTool*). Функции возвращают объекты, интерфейс которых определен в движке.
IClientDeveloperTool и IServerDeveloperTool. Не понимаю смысла в использовании
Python. Все пишется на C++. Просто необходимо обрабатывать события в данных объектах.
Также Developer должен переопределить поведение объектов на сцене(наследуется от IBaseObjectGeneral) и 
способ их создания (IMakerObjectCommon). Тот объект, который активно участвует в сцене, наследуется
от IActor. Далее для работы с GUI Developer наследуется от IGrahpicEngineGUI. В конструкторе
вызывает Load(путь к XML). Далее Connect(компонент,событие,обработчик).
 - Далее мышь и клавиатура: у IClientDeveloperTool есть метод int ConvertKeyEvent2Value(...) и 
int ConvertMouseEvent2Value(...). Значение, полученное от этих функции подается 
на логический уровень. Механизм конечного автомата по значению найдет ключ. Данный ключ для обработки
передается в обработчик этих ключей.

23.11.2012:
 - См. Architecture v0.4.eap и Architecture Included Headers.eap.
 - Game.exe -a s/c -p client.dll --p start with param ip=0.0.0.0 port=1000
 Т.е. Игровой движок один. параметры разные. Как то так:
 if(argv[1]=='s')
   new TClient
 else
   new TServer
25.11.2012:
  - Типы игр: Local, Online, Massive-Online. К слову о Master-Server, Slave-Server и Client.
  Local - в одном процессе, остальные в разных потоках.
26.11.2012:
  - Massive-Online - Система MasterServer-SlaveServer. Оптимизация. Распределение нагрузки и 
создание общей точки синхронизации.
Задачи Master - 1. Первичная точка доступа при регистрации соединения с абонентами.
                2. Распределение нагрузки среди Slave.
                3. Поиск по запросу у MasterServer и SuperServer соединения с Клиентом по его нику.
                4. Решения о синхронизации.
  - Муть с архитектурой. Пока GUI и GE доделаю. Совершенно не понятно что должно быть предоставлено 
  разработчику и как все это реализовать.
27.11.2012:
  - Будет каркас у сервера. Разработчику надо будет переопределить методы сервера.
28.11.2012:
  - Интерфейс GameLib.lib : 
  1. Client-Оффлайн, 2. Client-Онлайн, 3. Slave-Master, 4. Slave, 5. Master, 6. SuperServer.
  + путь к *.dll    
  - Скомпилировал и слинковал :)
  - Начинаю делать DLL.
29.11.2012:
  - Конвейер графического движка работает. Главный конвейер клиента тоже работает.
07.12.2012:
  - Мысли: 1. Камера должна быть в GameLib(Композиция). ICamera находится в Share. Звук и графика 
  владеют как агрегацией камерой.
  2. У объекта три сущности - графика, физика и звук.
  - Пока разбираюсь с выбором GUI. На выбор: MyGUI, CEGUI, Antisphere, librock, GWEN, Janella(мать 
  этих испанцев итить) и еще куча всякой хрени.
08.12.2012:
  - Вчера принял решение о переходе на MyGUI. Для освоения этой технологии необходимо:
  1. Собрать самостоятельно MyGUI_Engine.lib(dll). - от 1 недели до 1 месяца.
  2. Собрать Platform. - 1 неделя
  3. Собрать BaseManager (прослойка для работы с MyGUI). 1-2 дня
  4. Собрать пример для подтверждения того что владею технологией (демонстрация). 1-2 дня
  Заменять ли DXUT на MyGUI будет ясно на 2-3 этапе.
  - Данную версию считать свежей. Эксперименты здесь я пока не проводил. Ясно одно что настоящий 
  костяк конвейера клиента останется нетронутым. Добавится лишь GUI.lib, ну или еще заменится ли 
  DXUT на Platform.lib.
  - Архитектура точно будет известна  после 2-3 этапа (как раз когда будет известно будет ли жив DXUT).
11.12.2012:
  - За два дня скомпилировал и слинковал MyGUI!
  - Все работает и не тормозит в отличии от CEGUI.
  - Осталось придумать как это внедрить в multiplayer.
14.12.2012:
  - Тестовый пример собран. Заметил что обработка событий съедает львиную долю времени (до 12-15 мс)
от кадра. Если вырубить обработку событий будет под 1000 fps.
  - Потрачу время на Wrapper_MyGUI_Export. Мне кажется в этом что-то есть.
  завтра буду доделывать внедрение MyGUI. Потом Камера.
15.12.2012:
  - До сих пор делаю GUI. Все несколько сложнее чем казалось.
  Не хватает TManagerGUI. Static GetComponent.
19.12.2012:
  - Встраиваю GUI.lib в проект. Структурировал solution.
20.12.2012:
  - Доделал GUI. Столкнулся с одной проблемой, но решил ее.
  Дело вот в чем: если использовать статически скомпилированную библиотеку типа lib
для Exe и DLL, то это будет два разных адресных пространства.
Поэтому нужно компилировать MyGUI в виде DLL.
  - Есть одна недоделка - при переходе в full-screen происходит ResizeGUI, но когда
обратно ResizeGUI не проходит.
  - Задача - глюк с Tools GUI, resize, Camera, конечный автомат, 
21.12.2012:
  - Исправил глюк с некорректным ResizeGUI. Дело в том что DXUT вызывает Reset до реального
изменения размера окна. Мне кажется так и должно быть. Reset так и должен себя вести.
Сырость DXUT в том что нет события "переход в из оконного режима в полно экранное и обратно".
22.12.2012:
  - Блин. Когда создавал проект MyGUIEngine это был Dll-проект. Потом я его переделал в Lib.
А вот EditorFramework был изначально как Lib. Надо было не менять тип проекта, а создавать заново.
В проекте прописать define MYGUI_BUILD_DLL и все.
25.12.2012:
  - Мысль назвать игровой движок FullMaster или Tornado.
  Танки - это всего лишь пример использования. Надо поправить заголовок файлов.
26.12.2012:
  - Добавил класс контроля за кол-вом создаваемых объектов одного класса.
  Теперь если нужно ограничить кол-во создаваемых объектов нужно пронаследоваться
  от TOnly_N_Object и указать в конструкторе макс. кол-во объектов и 
  макросом NAME_CLASS прописать имя класса.
  - Перевожу GBaseLib, Share из Lib в Dll (надо так же и проект модулей конвертировать в Dll).
  - Потом нужно править архитектуру.
27.12.2012:
  - Делаю камеру. Для этого надо подготовить классы матриц (оптимизация).
  Оптимизирую: по сути в памяти у DX и Struct3D одно и тоже.
  Это можно применить в операциях над классом. А вот преобразовывать из Struct3D в DX 
  и наоборот придется что-то еще придумать.
09.01.2013:
  - Заменил все классы типа TMakerXXX на макрос.
  - Новогодний застой заканчивается. Все каникулы занимался поеданием еды, 
  играми и ничего-неделаньем.
  - Пусть будет имя "TornadoEngine"
11.01.2013:
  - Какие-то результаты по камере.
13.01.2013:
  - Сделать orient и учет координат и углов камеры. Учет больших изменений (list<>).
15.01.2013:
  - Основная проблема сейчас - непонятно поведение реализации класса TCamera. Нужно четкое определение.
  Думаю, лучше разделить на мелкие части с простым описанием и, комбинируя этими маленькими методами, 
  реализовывать крупные.
16.01.2013:
  - Наконец-то работает LookAt у камеры. Теперь, задав вектор нормали к Земле, можно управлять Roll камеры.
18.01.2013:
  - Составил План работ.
  - Сделал настройку путей к ресурсам движка (модули).
29.01.2013:
  - Конечный автомат готов. Для мэппинга клавиатуры(системные события) и HotKey.
  - Гибкий контейнер готов. Нужен в будущем для упаковка пакетов прикладного уровня.
  в нем сначала нужно описать схему контейнера (задать вектор). Далее, получив доступ
  по имени к памяти, назначить содержимое. В случае изменения кол-ва полей 
  вызвать Update().
30.01.2013:
  - Читаю boost. Тут есть все, что нужно. Подумываю над внедрением технологии.
  Можно заменить TMapDual на boost::bimap, TStateMachine на boost::msm.
07.02.2013:
  - Client знает о неком протоколе общения с абстракцией "сервер". 
  Сервер-Slave о таком протоколе ничего не знает (требуется только 
  переопределить чистые виртуальные методы).
08.02.2013:
  - Добавил в камеру привязку к объекту, перемещение свободной камеры с заданием скорости.
11.02.2013:
  - Делаю клиент-серверные отношения.
13.02.2013:
  - Освоил кватернионы. Применил в камере вместо корректировки по нормали к Земле.
  Всего 2 строчки кода заменяют огромное кол-во формул и расчетов. Очень удобно.
23.02.2013:
  - Правлю транспорт. Проблема в том максимальный размер пакета по UDP 1,5к.
  Значит если потребуется отправить пакет большего размер, нужно будет использовать либо класс-дозатор
  (дробление пакета и сборка) либо TCP канал.
  Еще существует проблема эффективного использования канала:
  либо засорить его полностью (когда пакеты отправляются без ожидания отправки предыдущих пакетов),
  либо неэффективно использовать (ожидание отправки предыдущих пакетов).
  Эта проблема может иметь место как на сервере (чаще всего) так и на клиенте.
28.02.2013:
   - Пока правлю транспорт. Систему массового обслуживания прежде надо разработать верхушку.
   Потом двигаться сверху в низ, выставить требования к интерфейсу транспорта. А не наоборот.

30.04.2013:
   - Разработка интерфейса Мелиссы закончена. Теперь надо удалить текущую Мелиссу из проекта и заменить
   на Melissa.dll и NET_Transport.dll.
   - По плану нужно релизовать абстрактные классы интерефейса.
	 - Для Melissa все-таки придется использовать классическую схему, которую используют при разработке Qt.
	 То есть вся иерархия классов не чисто абстрактная.

04.05.2013:
  - Требуется реорганизация Share и GBaseLib (сделать после Melissa):
   1. удалить неиспользуемые файлы.
   2. сделать прослойку между внешним пользователем и glib.
   3. переименовать библиотеки.
   4. переместить файлы в соответствующие библиотеки (Share<-->GBaseLib).
  - Доделать NET_Transport, Melissa и добавить DBLib (декабрь 2013).
07.05.2013:
  - Для переключения транспорта TNetTransport в быстрый режим надо прописать в свойствах проекта
  FAST_NET_TRANSPORT. Он выключит логирование, тем самым повысит скорость обработки пакетов.
  - Проблема нагруженности сервера при получении пакетов на высоких скоростях (более 100 Мбит/с).
  Не так критична, поэтому решаться должна после написания Melissa.
  Идеально для 100 Мбит 10 мс задержка и 150-250 пакетов в одной посылке (для NetDoser эта 
  информация будет полезна).
  - Идея для Дозера: при попытке отправить решать больше ли пакет определенного размера.
  Если больше, то будить поток и отправлять с помощью него так, что бы не перегружать трафик и сервер.
  Если меньше то просто отправить.
03.06.2013:
  Фактически транспорт готов
07.06.2013:
  После долгого и нудного обдумывания прихожу к выводу что нужно строить транспорт на TCP/UDP.
  В TCP десятилетиями апробировались технологии управления трафиком. Поэтому изобретать велосипед не буду.
  Стоит лишь научиться управлять TCP таким образом что бы контролировать процесс и подстраивать его под свои нужды.

  На высоких скоростях отрабатывал "вдумчивый" TCP, а на низком трафике быстрый и без инерционный.
09.06.2013:
  Два последних дня был в прострации. Думаю подсознание перезагружалось.
  Значит так: открывать один и тот же порт для TCP и UDP можно.
  connect под Windows работает с блокировкой.
  WSA_XXX может отслеживать события на Socket-ах.
  Осталось выяснить можно ли писать и читать в сокет из разных потоков.
14.06.2013:
  Более того можно открывать один и тот же порт для listen и для connect. 
  Надо использовать флаг reuse для сокета.
16.06.2013:
  Сетевой транспорт готов. Но не обошлось и без проблем.
  Дело в том что, при малом размере буфера на прием при передаче данных по TCP
  пакеты перетираются свежими пакетами. Думаю проблема в использовании на localhost или в WSA.
  Пока это неважно. Оставляю проблему до 17 июня. А сейчас Melissa (СМО).
21.06.2013:
  Проблема решена. Все дело в том что надо было отслеживать готовность отправить пакет по возвращаемому значению
  функцией send. Пакеты не затирались, они не были отправлены.
  Готовность к сборке Melissa. Но сначала надо собрать каркас серверного конвейера. Это я не учел.
  На это может уйти до 2-3 недель. Тут надо учесть возможность использовать в разных воплощениях.
  Как только конвейер будет готов, можно будет делать внутренности Melissa.
28.06.2013:
  Делаю конвейер сервера, точнее Slave реализацию. Наконец-то сдал ИТОК.
  Спать охота, часто засыпаю, когда никого нет. Зато после сна часто возникают интересные
  идеи.
02.07.2013:
  Я на распутье. Дело в том, что в качестве Графического движка можно использовать кучу бесплатных
  движков. С физикой дела обстоят так же. MyGUI я уже использую. А вот сетевых движков нет.
  Либо они платные, либо кривые и бестолковые.
  Таким образом все что от меня требовалось, так это написать игровой и сетевой движок.
  Но графический движок написан. На данный момент нет такой необходимости в выборе между графическими движками.
  Самое главное сейчас доделать Сервер, Melissa и внедрить физику.
  1. Доделать серверный конвейер (тяжко, спать охота) с учетом назначения Slave, Master, SuperServer.
  2. Доделать Melissa. Тут вся проблема в критерии готовности библиотеки. Нет тестов
  для точного понимания того, что все готово.
  Балуюсь Newton и Bullet(хотя нужно другим заниматься!). Они конкуренты, надо бы еще раз
  скачать ODE (она мне в первый раз не понравилась).
03.07.2013:
  Поправил TNetTransport_UDP. Заменил TArrayObject на std::map.
  Код стал меньше и понятнее. Вдобавок я избавился от зависимости от GBaseLib.
  Этот класс можно будет использовать там, где нет TCP.
  Думаю завтра начну править серверный конвейер, сегодня спал с 23-00 до 6-20. 
  Голова лучше соображает, чем вчера :). Мысля копится, думаю скоро разрожусь.
04.07.2013:
  Надо разработать внутренний протокол общения Мелиссы.
  Выбор стоит по внутренней организации классов Мелиссы.
  Либо делать очередь событий, куда будут складироваться события от транспорта 
  (обрабатывать их в Work), либо сразу напрямую обрабатывать события и добавлять в TSrcEvent.
  Во втором варианте метод Work выполняет роль таймера, например, если
  нужно ждать ответа от сервера на запрос.
07.07.2013:
  Окончательно Peace of Tanks.
  Плюс в заставке перед боем делать капитанские записи,
  типа 2+2=4, Земля вращается вокруг Солнца и т.д.
  Проанализировал кучу сетевых движков, ни одного нормального.
  Во всех исходниках нет даже std::map, не то что Boost-а.
  RakNet вообще кидалово. Cloud за 100$ в месяц.
08.07.2013:
  Менеджер сессий готов. Теперь надо найти общее между всеми сценариями
  и поместить в TBase.
11.07.2013:
  Все таки решил использовать BulletPhysics.
  1. Код Bullet более качественнее. В Newton-е код сырой, хотя фич по отладке больше.
  То же самое что выбирать между мониторов с плохим качеством отображения, но с закрепленным на нем
  зонтиком, открывашкой для пива и ручкой на веревке, и качественным монитором, но без подставки.
  В движке главное качество кода и возможность для наращивания функционала, а в Newton эти возможности
  уже нарастили, но код сырой.
  2. Bullet используется в GTA 5, а это уже что-то да значит. Более шикарных аварий при столкновении
  автомобилей в играх я никогда не видел.
  3. Взгляд больше цепляется за Bullet, приятнее разбираться - скорее как бонус, не сильный аргумент.
18.07.2013:
  Вроде транспорт сделал, а сейчас гляжу - максимум то для функции WSAWaitForMultipleEvents сокетов
  равен 64. Под Windows XP это точно. Надо посмотреть как под Windows 7 и под Linux (poll).
  Как выход - либо опрос сокетов частями по 64 сокета, либо через RegisterWaitForSingleObject.
19.07.2013:
  Ха! В очередной раз охреневаю от MS. Есть такая функция WSAPoll, но она доступна с Windows Vista.
  Аналог poll, надо смотреть сколько можно сокетов отслеживать. Если будет достаточно
  много (хотя бы 500), то можно будет под Windows XP использовать многопоточную схему, а под
  Windows 7 WSAPoll.
22.07.2013:
  На фиг WSAPoll. С помощью потоков и событий ждать события от сокета.
  MainThread владеет hEvent, другие рабочие потоки сообщают с помощью SetEvent
  о получении пакета.
24.07.2013:
  Boost использует Completion Port под Windows (очень мощная штука). 
  Пока сделал транспорт на WSAWaitEvent,
  теперь добавлю транспорт, основанный на Boost(но старый транспорт оставлю). Использую Boost 1.54.
  Т.о. будет 3 вида транспорта (Boost, TCP_UDP(Win32) и UDP(Win32/Linux)).
25.07.2013:
  С вводом boost можно полностью отказаться от glib и GBaseLib. Сократит кол-во исходников,
  но в то же время будет жесткая завязка на boost.
06.08.2013:
  С помощью boost asio под Windows XP максимальное кол-во соединений - 156, 
  под Windows 7 - 500 (и это не предел).
  Перешел с async_connect на connect, теперь стало 220, но думаю дело не в этом, либо
  памяти мало либо ОС другую надо.
  Странно поведение CPU Intel Core2Duo E6400. Не тянет(до 100%) даже 100 UDP 1000 мс 1 пакет по 1350 байт,
  хотя Intel Core2Duo E8400 и Core2Duo E7400 тянут хоть 220, даже не напрягаясь (2-5%).
  И не понятно то ли дело в процессоре, то ли в ОС, то ли в объеме памяти.
  Дома то у меня Win7, 4 Гб и все тянет спокойно. В любом случае движок уже на что-то да способен.

  Будем считать что транспорт готов. Главное что бы комп держал 
  20 пакетов по 1350 байт с задержкой 100 мс на 500 клиентов (что эквивалентно 10000 клиентам
  на 1 пакет на 100 мс). Что для пакета в 1350 байт ооочень много, обычно пакет размером 100-200 байт(то есть 
  запас в 10 раз, а это вообще 100 000 клиентов). "Держать" - значит нагрузка 10-20% от одного ядра. 
  Что бы оставалось время на другие задачи. То есть для 4 ядерного процессора надо примерно 5% от общей нагрузки.
  Для сервера использовать CPU x8 Xeon X5550HT 2666 MHz (надо стоимость узнать).
07.08.2013:
  CPU x8 Xeon X5550HT 2666 MHz стоит 1600$, но это для многопроцессорных систем. Думаю
  Intel Core i7 (1000$ с 6 ядрами) хватит, 32 Гб памяти.
14.08.2013:
  BOOST_FOREACH нельзя работать с map и set, если нужно менять содержимое внутри.
	Проблема решена: использовать BOOST_FOREACH(TMapClass::value_type& bit, mMap)
	                                bit.second->Func();
27.08.2013:
  Вход Slave в состав кластера готов.
  Завтра надо будет сделать авторизацию клиента.
29.08.2013:
  Для сценариев решил переделать механизм обмена пакетами. Модель Self-To-Self, то есть
  один класс сценария передает данные тому же классу, т.о. владелец сценария не знает о типе
  пакета, а знает лишь какому сценарию предназначен пакет.
  Доделать контекст сценария, продумать.!!!!!!
30.08.2013:
  Что бы сразу разобраться по сценариям:
    1. Сначала была идея создания сценария для одной цели. То есть уровни, владеющие
  сценариями не знают о типах пакетов. Пакеты передаются объекту, который решает
  какому сценарию предназначен пакет. Далее сценарий решает что делать с пакетом.
  То есть возникает идея Контроля событий сценариев TControlScenario
    2. Далее возникла сложность. Т.к. прием пакетов идет только в сценарии, то создание нового сценария,
  ассоциированного с данным соединением, невозможно. Возникла идея создания контекста сценария - IContextScenario.
  Т.о. сценарий существует всегда, он лишь является моделью поведения. А контекст это данные, с которыми
  работает сценарий. Эти данные привязаны к сессии(хотя могут быть привязаны к чему угодно).
    3. Далее возникает проблема как различать активен ли сценарий? Например, перекоммутация клиента.
  Началась перекоммутация (сократим название - RCM). Контекст ей задан - это C1. Возникла задача объединения
  в группу, значит понадобилась еще одна RCM. Вызвали Begin, спросилил активен ли он.
  Как различить активность? Контекст тот же, сценарий тот же. Ведь вопрос активности
  может задать другое выполнение с тем же контекстом. 
  Решение: bool Begin(IContextScenario* pCSc)
05.09.2013:
  Кое-что о сценариях. Сценарий - модель, контекст сценария - данные. Сценарий
  это своего рода машина состояний, логика.
  Мне совершенно не нравится такой тесный симбиоз (слишком много контекстных функций вызывается
  внутри сценария). Надо бы часть этих вызовов объединять и вынести в функции контекста.
  Ну что бы было больше кода в самом контексте, меньше вызовов типа Context()->.

23.09.2013:
  Вернулся из Турции 18 сентября, пишу только сейчас О_о.
  Есть реальная проблема для визуализации результатов работы движка. И сейчас она ощущается
  очень остро. Сначала сделаю отображение консоли, которая отображается по ключу -c.
  Потом хочу серваку привинтить GUI. GUI можно будет управлять непосредственно через DevTool, 
  но модуль графики будет не таким каким он является в клиенте.
  В таком виде отладка Мелиссы будет эффективней, и работа над проектом будет идти быстрее.
24.09.2013:
  Правлю ядро. Добавляю GUI в сервер. Появляется дублирование кода. Это дублирование 
  надо потом свести в IGame.
  Хехе, fps для сервера то 10! Больше и не надо!
  Все равно данные обновляются не чаще.
26.09.2013:
	Добавил модуль QtLib, теперь для отладки можно использовать GUI.
	Вместо 3 функций использовать 5, заменить GetServerDeveloperTool
	на GetSlaveDeveloperTool, GetMasterDeveloperTool, GetSuperServerDeveloperTool.
	Завтра сделаю.
27.09.2013:
	Все довожу до ума QtLib. Сделал вызов кванта времени из потока Qt для функции.
	Теперь когда нужно что-то изменить в форме, просто вызвать с указанием функции
	и произвести изменения в потоке Qt в какой-то из функций.
03.10.2013:
  Доделать модуль "Таймер"!!!
07.10.2013:
  Доделан Таймер. Поправил ядро с учетом Таймера. Убрал Refresh за ненадобностью.
  Ладно, доделываю LoginClient. Самый тяжелый сценарий, еще тяжелее будет
  перекоммутация, но это фактически 90% всей работы.
09.10.2013:
  Привести в соответствие сценарий LoginClient. 
  ScenarioLoginClient->ColdMaster->HotMaster->Accept или Reject
  Accept -> Queue или Accept (в зависимости от нагрузки серверов)
  -> Context->ScenarioLoginClient
  Проект на Github.com :). Надеюсь, кому-то проект понравится. Но лучше все писать на английском,
  по крайней мере перевести.
10.10.2013:
  Переделываю ScenarioLoginClient, с учетом добавление в очередь ожидания клиента,
  если нет места на серверах.
26.10.2013:
  Идея поместить в ScenarioLoginClient 4 части: Client, Slave, Master и SuperServer,
	каждая из которых отвечает за обработку пакетов, предназначенных, соответственно,
	тезкам. Есть базовый класс, от которого наследуются эти классы, в нем должны быть определены
	все пакеты, а базовый пакет должен быть в ScenarioLoginClient, в нем появляется поле
	char where, то есть кому предназначен пакет, т.о. ScenarioLoginClient определяет
	по нему какой из частей отдать пакет.
	Далее внутри контекста опять таки должно быть 4 части (C,S,M,SS).
	Данное решение имеет своей целью лишь повышение читабельности кода и понижение сложности класса ScenarioLoginClient.
30.10.2013:
  Косметические изменения в проекте. Изменил типы модулей с lib на dll, поменял имена
  с неосмысленных Melissa на MMOEngine и т.д.
07.11.2013:
  Отладка багов работы сценариев. Подкручиваю болты.
08.11.2013:
  LoginClient готов! Осталось проработать варианты обрыва связи на разных этапах выполнения сценария.
	Потом доделать сценарии Дисконнекта клиента. И останется только перекоммутация клиента и все, движок ММО закончен!
	И еще, надо протестировать в интернете авторизацию клиента.
12.11.2013:
  Доделал сценарии DisconnectClient для Клиента и Slave.
  Сценарий LoginClient доделал с учетом надежности (например что делать при дисконнектах на любой стадии сценария).
  Осталось перекоммутация и проверка в интернете.
14.11.2013:
  Оживил Конвертер Меш. При загрузке Клиента Танков загружается Ангар и Тигр II.
15.11.2013:
  Для завершения работ над MMOEngine нужно:
  I Реализовать класс статистики по Клиентам, которые находятся в группе и существуют в системе,
    поместить этого класса в: AddSlave, DeleteSlave, AddClient, DeleteClient, CreateGroup, LeaveGroup,
    DestroyGroup. +
  II 
    1. Обмен для клиентов при формировании Группы на конкретном Slave производится таким образом:
    если Клиент Группы находится не на своём Slave, то он перекоммутируется, а какой-то  другой Клиент,
    который находится на целевом Slave, копируется туда, где находился Групповой Клиент. То есть производится
    обмен, что бы нагрузка была неизменна. Если там нет Клиентов, то не копируется.
    2. Обмен производится для Клиентов не состоящих в Группе только если:
        - контекст Клиента не занят в выполнении сценария перекоммутации.
    3. Поиск Slave, на котором будет находится Группа надо производить по минимуму
    занятых в Группе Клиентам (см. TStatisticaClientInGroup ).
  III
    Доделать сценарии SendToClient и RecommutationClient (он должен быть реализован примерно так же как
    и LoginClient). В этих сценариях не хватает определения что Клиент не успел подконнектиться
    к Slave.

23.11.2013:
	- В движке сделал фокус (управляю танком с сервера на клиенте), 
	думаю всем понравиться. Не очень понравилось. Ну, если я физику сделаю и им не понравится,
  это будет уж слишком.
  - Сделал сценарий рассылки списку Клиентов пакета из любой точки системы (SendByClientKey).
25.11.2013:
  - Правил глюки. Доделал сценарий авторизации Клиента с учетом если Клиент не успел подконнектиться.
  - Остался только сценарий Перекоммутации Клиента сделать и все.
27.11.2013:
  - Глюк при отрисовке на видеокарте GeForce 7600 GS, как будто части отрисовываются без применения
  теста Z буфера. Хотя на встроенных Intel-вских картах и Radeon все отрисовывается изумительно.
29.11.2013:
  - Добавил поверхность в устройство с помощью SetDepthStencilSurface. И проблема решилась.
11.12.2013:
  - Технология RSA и AES из openSSL освоена. Замеры скорости шифрования в doc.
  Вот как это будет:
  1. Этап обмена ключами.
  На уровне транспорта при попытке соединения происходит генерация RSA ключа (Клиент).
  Потом Клиент отсылает в открытом виде публичный ключик Серверу. 
  Сервер генерирует AES ключ и шифрует его публичным ключом RSA Клиента и отсылает Клиенту.
  Клиент дешифрует пакет и теперь ключи AES есть у обоих.
  2. Обмен пакетами, шифрованными с помощью AES. Т.к. AES не скажет была ли попытка подмены, то
  пакет должен быть дополнен MD5 суммой. То есть sizePacket + 16 байт.
  Осталось дооформить замеры и написать классы, реализующие RSA, AES и MD5 для удобства.
12.12.2013:
  - Как в TCP определить наачало и конец пакета? Ведь если прописать в пакете в начале размер и 
  зашифровать, то можно подменить размер и тогда транспорт не только потеряет этот пакет, но и 
  вообще потеряет связь.
14.12.2013:
  - Сделал шифрование. Теперь никто не сможет:
  1. Узнать какими данными обмениваются участники MMO. +
  2. Подменять данные своими (фактически получить управление). +
  3. Уронить сервер. ???
  Но не обошлось и без проблем: генерация ключа для RSA очень интересный процесс.
  Скорость создания ключа варьируется от 200 мс до 7-8 секунд. Таким образом 
  задержка коннекта Клиента к Slave может быть разной. Иногда у Мастера
  таймаут может закончиться. Решение: создание RSA ключа во время запуска приложения.
  RSA ключ один на весь Менеджер ManagerContextCrypt.
16.12.2013:
  - Существует две стороны вопроса о безопасности:
  1. Безопасность Клиента. Что бы нельзя было украсть данные и чтобы нельзя было перехватить управление.
  2. Безопасность Сервера. Что бы нельзя было уронить Сервер и запороть работу Сервера. 
  Первая проблема успешно решена. Используется RSA и AES.
  Вторая проблему несколько шире. 
    Во-первых, можно использовать исходный код Клиента и отправлять некорректные 
  пакеты (проблема Взломанного Клиента). 
    Во-вторых, пакеты, которые летают между компонентами Сервера, можно 
  перехватывать, подменять, менять.
    Проблема Взломанного Клиента решается просто: проверять размер и корректность пакетов Клиента
  в каждом сценарии отдельно.
    Вторая проблема решается невозможностью подмены пакетов. Вставка в начало пакета до шифрования
  счетчика, который увеличивается при отправке. На той стороне контролируют корректность пакета по 
  этому счетчику. Таким образом отправить повторно зашифрованный пакет не получится. Либо его не 
  дешифруют, либо счетчик не подойдет.
    Далее еще один момент Флаг использования шифрования - действует на всю систему в целом.
  Либо он используется и везде в Клиенте, Мастере и т.д. либо нигде.
    Шифруется только TCP. Передавать данные по UDP и пытаться их шифровать - глупо.
  Управляющие команды по UDP не передают. НО есть такой сценарий как ScenarioFlow.
  В нем используется как TCP, так и UDP. В остальных сценариях используется только TCP.
18.12.2013:
  - Перекоммутация завершена! Осталось провести тесты, когда Дисконнект любого компонента может
  произойти в любой момент. И потом можно даже на GitHub выложить.

21.12.2013:
	- Проблема утечки памяти. Не зависит от объема трафика, но зависит от кол-ва пересланных пакетов.
	Растет 1 Мб на одно соединение (каждые 100 мс) за 5 минут на Slave. На Клиенте поменьше в 2-3 раза.
  Решено. Надо было Clean для AES после каждого шифрования.

10.01.2014:
	- Прочитал тут про атаку man-in-the-middle. А ведь моя реализация уязвима.
	Как вариант решения данной проблемы - сертификация сообщений RSA public key.
	А точнее X.509.

13.01.2014:
  - На хрен X.509. Нашел способ решения проблемы MITM. Но для ее решения нужно чтобы была
  запись о клиенте в БД.
  Алгоритм:
  1. Клиент отсылает Серверу RSA public key. В ответ AES ключ. Все как обычно.
  2. Сценарий Авторизации: Клиент отсылает MD5(LoginPassword), AES(RSA public key).
  AES зашифрован ключом SHA1(LoginPassword). 
  MD5(LoginPassword) нужен для поиска записи о Клиенте в БД.

  То есть для реализации алгоритма всего то надо добавить дополнительную функцию в Сценарий и новый
  ответ Сервера IsSessionSecurity.
  
  1. RSA
  2. MD5(LP), AES(RSA), key for AES is SHA1(LP)
14.01.2014:
  - Пока реализовал на стороне Клиента в сценарии алгоритм. Завтра сделаю Серверную часть.
20.01.2014:
  - Все готово.
25.03.2014:
  - Скорректировать правильные английские названия. Common - общественный, публичный, а вот
  General - общий, общего характера. То есть IBaseObjectCommon => IBaseObjectGeneral
  и т.д.
27.03.2014:
  - Сформировать фронт работ для определения ServerCore.dll в качестве модуля. 
  Соответственно должен быть интерфейс для данного модуля.
  Вот одна из основных проблем: когда Клиент хочет вступить в бой - он отсылает
  запрос Slave. Тот в свою очередь транслирует этот запрос мастеру.
  Мастер принимает решение сгруппировать Клиентов. Существует два варианта развития событий: 
  1. Клиент переходит на другой Slave
  2. Клиент остается на том же Slave.
  В незавимости от варианта далее Slave передает событие создания группы разработчику и
  тот в свою очередь формирует на сервере группу для проведения боя (Комната, Сцена).
  Предположим один из клиентов не захочет дожидаться окончания боя и выйдет из MMO-группы.
  ММО движок исключит его из группы, а вот серверная реализация не должна этого делать.
  Серверная часть хранит образы Клиентов, по которым она можно сделать запись в БД или 
  оповестить о событиях. Потом клиент захочет зайти в новый бой. Его могут переместить на другой
  Slave или оставить на старом. Создаться новая ММО-группа и он попадет в новую Комнату на сервере.
  
  Физическая составляющая и БД должны быть представлены лишь интерфейсами (Фасад библиотеки).
  Так будет проще.
  Далее встает вопрос создавать ли отдельный модуль ServerLib?
21.04.2014:
  - Мастер оценивает безопасность сессии с Клиентом, а вот при коннекте Клиента со Slave - нет.
  Поэтому требуется доделать сценарии Авторизации Клиента и Перекоммутации Клиента с учетом
  этих правок.
  Также добавлена возможность проверки сессии SuperServer-ом и Мастером - 
  метод IsSessionSecurity перемещен из TMaster в TBaseServer.
14.06.2014:
  Убрал зависимость от Directx функций из ShareLib. Часть переписал сам, часть взял из исходников Wine.
11.07.2014:
  Разработка концепции ядра идет полным ходом. Исправил глюк в MMOEngine 
  (сценарий авторизации клиента при попытке соединиться с мастером отсылал пустой эхо пакет, 
  что противоречило системе поиска хака) и 
  MathTools (умножение матриц было напрямую через pOut, а нужно было через временную переменную).
14.07.2014:
  Придумал идею механизма "почкования". То есть можно будет обойтись без создания
  объекта модуля, а запросить экземпляр модуля у самого модуля.
  + virtual AdapaterBaseModule* NewExample() = 0;
  + virtual void DeleteExample(AdapaterBaseModule* ptr) = 0;
15.07.2014:
  Ядро пишется в AE. Основные механизмы описаны. Все вроде в норме. Надо еще
  описать как происходит запуск и работа ядра.
21.07.2014:
  Застрял на том как же должно выглядеть ядро. На самом деле надо смотреть и на то, что уже сделано, а не
  только что должно быть.Попробую сделать еще одну версию ядра и вставить в параллель со старым и методом 
  сравнения выявить чего там не хватает (применю так сказать инженерный подход).
23.07.2014:
  Придумал как избавиться от различий между Клиентом и Сервером в ядре. Теперь есть только одна сущность.
  Ядро имеет pure virtual методы и IDevTool.
  + virtual int AdapaterBaseModule::GetModuleID() = 0;
25.07.2014:
  Ядро новое готово, осталось проблему решить с Адаптерами. А именно: непонятно почему появляется 
  зависимость Графического движка от Камеры и GUI. Что, может быть, вполне логично.
  Но как это должно выглядеть в конечном итоге?
29.07.2014:
  NetTransport является вспомогательной частью MMOEngine. Сам TNetTransport должен находиться в модулях.
  А INetTransport - в адаптерах.
30.07.2014:
  Возникает проблема привязки к MyGUI: если из графического движка выкинуть поддержку
  MyGUI - разработчику придется переписывать все что он написал под другой GUI.
  Как способ решения этой проблемы (и не только этой, но и еще и Qt) - 
  дать разработчику реализовать интерфейс GUI для графического движка самостоятельно.
  Или как вариант указывать графическому движку какой GUI использовать.
31.07.2014:
  MMO и GE пока реализованы в виде полноценных движков. Но должно быть так:
  есть движок и есть реализация адаптера, использующего этот движок для реализации
  для разработчика.
  Думаю об интерфейсе адаптера для ММО.
01.08.2014:
  Prototype<----Adapter<>----Module
  Загрузкой ресурсов должно заниматься Ядро.
  Графика должна отображать, Физика просчитывать взаимодействия.
06.08.2014:
  Скомпилировал и запустил. Правда, все упало. Но это уже близко в финальному виду.
07.08.2014:
  Проверил Qt и MMO для серверов. Работает. Осталось проверить MMO для клиента, графику и MyGUI.
  MyGUI отрабатывает.
11.08.2014:
  В общем все работает. Далее - коррекция описания в EA ядра.
  Потом хочу написать статью в Хабрахабр.
  Думаю написать 2 статьи. О ММО движке и игровом движке.
  Все таки у меня больше гордости вызывает сетевой движок, там я 
  написал полную документацию, кроссплатформенность и большие возможности. 
  Сам же игровой движок у меня особо не вызывает восторгов.
15.08.2014:
  На сайте приняли только статью о ММО. Думаю дальше написать LoadSaveModel.dll, в котором
  будет загрузка моделей. Перенести из ядра и Share.dll.
  Далее AdapterGraphicEngine_OGRE.dll.
  Потом AdapterPhysicEngine_Bullet.dll.
19.08.2014:
	При таком подходе достичь главной цели - Игра, будет невозможно.
	Надо постепенно идти к плану Прототип-Адаптер-Модуль.
	Пускай пока будет прямой доступ к ОГРУ и Буллет у разработчика. Главное что делать с синхронизацией
	общих объектов (блин, вот почему я назвал IBaseObjectCommon).
	Это самая главная проблема над данный момент. Physic-Graphic-Sound синхронизация.
22.08.2014:
  Начал осваивать OGRE. Все для этого подготовлено. Ядро переделал.
  Особая благодарность Vredskiy, благодаря его проектам firstgame и ragdoll_sample
  я смог сделать встраивание и синхронизацию OGRE-Bullet. Почерпнул оттуда много идей.
  Mingun, спасибо за инвайт!
  Lair может и прав на счет надежности ММО. Но как эту проблему решить? Делать "напарника"
  для каждого компонента серверной части или создавать инспектора, что бы он контролировал
  компоненты?
  Если и делать, то так: Мастер и СуперСервер скидывают всю информацию через канал TCP,
  у каждого Мастера и СуперCервера есть свой напарник.
  Когда кто-то падает, то напарник загружает информацию и создает соединения со Slave.

  Нашел недоработку. Если создать два объекта (например Client и Client) в одном процессе,
  то статический объект в транспорте будет замещен и первый объект будет пользоваться
  транспортом второго. Исправил.

	Только сейчас начинается работа над движком. Связка OGRe c Bullet-ом. Многострадальное ядро,
	которое я уже 5 раз правлю.
23.08.2014:
	Цель на данный момент - запуск клиента с окном MyGUI.
25.08.2014:
  DXUT умер. Да здравствует, DXUT! Запустил MyGUI, но пока только в одном потоке, правда.
  Сделал. Но осталось разобраться с ресурсами (настроить расположение, продумать названия папок).
  Выложусь на GitHub.
26.08.2014:
  Добавил функцию конвертации utf-8 -> cp1251.
  DemoKeeper из MyGUI совершенно не подходит.
//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------
    TODO:

28) Выбор карты и понятие "карта" - 
41) проблема совместимости загрузки карты на клиенте и сервере -
67) Реализовать классы поведения: Tree, Terrain и т.д. -
68) Формат карты и моделей -
76) таблица эффектов id-path
77) path Effect содержит id_model и описание поведения. MakerEffectDX - 
78) Продумать архитектуру с учетом возможности оптимизации при расчете на клиенте физики в зависимости от расстояния до камеры
79) Продумать архитектуры на сервере с учетом отправки на клиента не всех стримов танков, в зависимости от расстояния и возможности визуального контакта.
82) Добавить управление освещением в BigJack - 
89) BSP класс (кажется красно-черные деревья называется)
91) Загрузка карты
94) Клиент-серверные отношения, slave, master, superserver, client
96) Глюк когда под релизом запуск с отладкой и без нее - возникает разница в расположении камеры.
97) Общеизвестный глюк под Windows XP в Boost: QueryPerformanceCounter возвращает false.
Эта ситуация возникает когда происходит вызов из разных потоков this_thread::sleep_for().

98) В мастере std::list<std::list<id_session> > mListGroupWaitRecommutation - ожидающих вход в группу
99) Переделать все библиотеки из *.lib в *.dll.
100) В DeveloperTool убрать функцию, возвращающую TLogger* (???).
101) Переименовать BigJack->GraphicEngine, Robert->PhysicEngine, Melissa->MMOEngine, 
заодно 99 задание.

102) sendxxx лишние 2 байта,
103) при sendxxx на slave при авторизации клиента падает.
//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------
    INFO


//----------------------------------------------------------------------------------------------------------------
//----------------------------------------------------------------------------------------------------------------
    BUG:

*/

#endif